[{"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\load.py , True, 1638422076.0356705 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 23:15:14 2021 -0600", "msg": "1638422076.0356705_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\load.py , True, 1638422076.0356705 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/load.py b/explore/load.py", "add": ["+  return pd.read_csv(filename, index_col=0)"], "sub": ["-  return pd.read_csv(filename) #demo", "-    df.to_csv(\"clean3.csv\")"]}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+# # cdf = load(\"clean.csv\")", "+# plot(cdf)"], "sub": ["-# cdf = load(\"clean.csv\")", "-plot(cdf)"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 23:14:36 2021 -0600", "msg": "1638422076.0356705_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+# # cdf = load(\"clean.csv\")", "+# plot(cdf)"], "sub": ["-# cdf = load(\"clean.csv\")", "-plot(cdf)"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\load.py , True, 1638421930.1531742 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 23:12:57 2021 -0600", "msg": "1638421930.1531742_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\load.py , True, 1638421930.1531742 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/load.py b/explore/load.py", "add": ["+    '''clean(df) takes as input a dataframe and fixes any data errors", "+", "+    Fill in missing values when appropriate", "+    # LATITUDE", "+    # LONGITUDE", "+    # BEAT_OF_OCCURRENCE", "+", "+    # MOST_SEVERE_INJURY (?)", "+", "+    Do not fill in missing values", "+    # STREET_DIRECTION", "+    # STREET_NAME", "+    # INJURIES_TOTAL", "+    # INJURIES_FATAL", "+    # INJURIES_INCAPACITATING", "+    # INJURIES_NON_INCAPACITATING", "+    # INJURIES_REPORTED_NOT_EVIDENT", "+    # INJURIES_NO_INDICATION", "+    '''", "+    print(\"Number of observations with nan, Before\", df.isnull().any(axis=1).sum())", "+", "+    # Fix BEAT_OF_OCCURENCE", "+    _df = df[df[\"BEAT_OF_OCCURRENCE\"].isna() & df[\"LATITUDE\"].notnull()]", "+", "+    df_with_beat_and_ll = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].notnull()]", "+    for row in _df.iterrows():", "+        idx = row[0]", "+        row = row[1]", "+        latitude = row[\"LATITUDE\"]", "+        longitude = row[\"LONGITUDE\"]", "+        # Get differences", "+        df_with_beat_and_ll[\"latitude diff\"] = abs(df_with_beat_and_ll[\"LATITUDE\"] - latitude)", "+        df_with_beat_and_ll[\"longitude diff\"] = abs(df_with_beat_and_ll[\"LONGITUDE\"] - longitude)", "+        df_with_beat_and_ll[\"abs diff\"] = ((df_with_beat_and_ll[\"latitude diff\"]) ** 2) + (df_with_beat_and_ll[\"longitude diff\"]) ** 2", "+", "+        # Index of row with closest coordinates", "+        closest_idx = df_with_beat_and_ll[\"abs diff\"].idxmin()", "+        # Get beat and insert", "+        predicted_beat = df_with_beat_and_ll.loc[closest_idx, \"BEAT_OF_OCCURRENCE\"]", "+        df.loc[idx, \"BEAT_OF_OCCURRENCE\"] = predicted_beat", "+", "+    # Fix LONGITUDE and LATITUDE", "+    beat_to_ll = {} # Dictionary containing mean latitude and longitude for each beat ID", "+    _df = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].isna() & df[\"LATITUDE\"].isna()]", "+    for row in _df.iterrows():", "+        idx = row[0]", "+        row = row[1]", "+        beat = row[\"BEAT_OF_OCCURRENCE\"]", "+        if beat not in beat_to_ll:", "+            same_beat_df = df_with_beat_and_ll[df_with_beat_and_ll[\"BEAT_OF_OCCURRENCE\"] == beat]", "+", "+            # There are no existing entries of this beat ID that have lat and long values", "+            if not len(same_beat_df.index):", "+                continue", "+", "+            mean_lat = same_beat_df[\"LATITUDE\"].mean()", "+            mean_long = same_beat_df[\"LONGITUDE\"].mean()", "+", "+            beat_to_ll[beat] = (mean_lat, mean_long)", "+        else:", "+            mean_lat, mean_long = beat_to_ll[beat]", "+", "+        df.loc[idx, \"LATITUDE\"] = mean_lat", "+        df.loc[idx, \"LONGITUDE\"] = mean_long", "+", "+    # Fix MOST_SEVERE_INJURY (the 11 observations) -- Update: I chose to drop them instead", "+    # _df = df[", "+    #     df[\"MOST_SEVERE_INJURY\"].isna() &", "+    #     df[\"INJURIES_TOTAL\"].notnull() &", "+    #     df[\"INJURIES_FATAL\"].notnull() &", "+    #     df[\"INJURIES_INCAPACITATING\"].notnull() &", "+    #     df[\"INJURIES_NON_INCAPACITATING\"].notnull() &", "+    #     df[\"INJURIES_REPORTED_NOT_EVIDENT\"].notnull() &", "+    #     df[\"INJURIES_NO_INDICATION\"].notnull()", "+    # ]", "+    # # for row in _df.iterrows():", "+    #     idx = row[0]", "+    #     row = row[1]", "+    #     # Doesn't make sense! See question 1i", "+    #     assert (", "+    #         row[\"INJURIES_FATAL\"] == 0 and", "+    #         row[\"INJURIES_INCAPACITATING\"] == 0 and", "+    #         row[\"INJURIES_NON_INCAPACITATING\"] == 0 and", "+    #         row[\"INJURIES_REPORTED_NOT_EVIDENT\"] == 0 and", "+    #         row[\"INJURIES_NO_INDICATION\"] == 0", "+    #     )", "+    #     df.loc[idx, \"MOST_SEVERE_INJURY\"] = \"N/A\"", "+", "+    print(\"Number of observations with nan, Intermediate\", df.isnull().any(axis=1).sum())", "+", "+    # Drop observations with latitude and longitude = 0", "+    df = df[df[\"LATITUDE\"] != 0][df[\"LONGITUDE\"] != 0]", "+", "+    # The rest, as described, we just drop", "+    df = df.dropna()", "+", "+    print(\"Number of observations with nan, After\", df.isnull().any(axis=1).sum())", "+    print(\"Number of observations after cleaning:\", len(df.index))", "+", "+    print(\"Writing to csv\")", "+    df.to_csv(\"clean3.csv\")", "+    return df"], "sub": ["-  '''clean(df) takes as input a dataframe and fixes any data errors", "-  '''", "-  print(\"Number of observations with nan, Before\", df.isnull().any(axis=1).sum())", "-", "-  # Fix BEAT_OF_OCCURENCE", "-  _df = df[df[\"BEAT_OF_OCCURRENCE\"].isna() & df[\"LATITUDE\"].notnull()]", "-", "-  df_with_beat_and_ll = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].notnull()]", "-  for row in _df.iterrows():", "-      idx = row[0]", "-      row = row[1]", "-      latitude = row[\"LATITUDE\"]", "-      longitude = row[\"LONGITUDE\"]", "-      # Get differences", "-      df_with_beat_and_ll[\"latitude diff\"] = abs(df_with_beat_and_ll[\"LATITUDE\"] - latitude)", "-      df_with_beat_and_ll[\"longitude diff\"] = abs(df_with_beat_and_ll[\"LONGITUDE\"] - longitude)", "-      df_with_beat_and_ll[\"abs diff\"] = ((df_with_beat_and_ll[\"latitude diff\"]) ** 2) + (df_with_beat_and_ll[\"longitude diff\"]) ** 2", "-", "-      # Index of row with closest coordinates", "-      closest_idx = df_with_beat_and_ll[\"abs diff\"].idxmin()", "-      # Get beat and insert", "-      predicted_beat = df_with_beat_and_ll.loc[closest_idx, \"BEAT_OF_OCCURRENCE\"]", "-      df.loc[idx, \"BEAT_OF_OCCURRENCE\"] = predicted_beat", "-", "-  # Fix LONGITUDE and LATITUDE", "-  beat_to_ll = {} # Dictionary containing mean latitude and longitude for each beat ID", "-  _df = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].isna() & df[\"LATITUDE\"].isna()]", "-  for row in _df.iterrows():", "-      idx = row[0]", "-      row = row[1]", "-      beat = row[\"BEAT_OF_OCCURRENCE\"]", "-      if beat not in beat_to_ll:", "-          same_beat_df = df_with_beat_and_ll[df_with_beat_and_ll[\"BEAT_OF_OCCURRENCE\"] == beat]", "-", "-          # There are no existing entries of this beat ID that have lat and long values", "-          if not len(same_beat_df.index):", "-              continue", "-", "-          mean_lat = same_beat_df[\"LATITUDE\"].mean()", "-          mean_long = same_beat_df[\"LONGITUDE\"].mean()", "-", "-          beat_to_ll[beat] = (mean_lat, mean_long)", "-      else:", "-          mean_lat, mean_long = beat_to_ll[beat]", "-", "-      df.loc[idx, \"LATITUDE\"] = mean_lat", "-      df.loc[idx, \"LONGITUDE\"] = mean_long", "-", "-  # Fix MOST_SEVERE_INJURY (the 11 observations) -- Update: I chose to drop them instead", "-  # _df = df[", "-  #     df[\"MOST_SEVERE_INJURY\"].isna() &", "-  #     df[\"INJURIES_TOTAL\"].notnull() &", "-  #     df[\"INJURIES_FATAL\"].notnull() &", "-  #     df[\"INJURIES_INCAPACITATING\"].notnull() &", "-  #     df[\"INJURIES_NON_INCAPACITATING\"].notnull() &", "-  #     df[\"INJURIES_REPORTED_NOT_EVIDENT\"].notnull() &", "-  #     df[\"INJURIES_NO_INDICATION\"].notnull()", "-  # ]", "-  # # for row in _df.iterrows():", "-  #     idx = row[0]", "-  #     row = row[1]", "-  #     # Doesn't make sense! See question 1i", "-  #     assert (", "-  #         row[\"INJURIES_FATAL\"] == 0 and", "-  #         row[\"INJURIES_INCAPACITATING\"] == 0 and", "-  #         row[\"INJURIES_NON_INCAPACITATING\"] == 0 and", "-  #         row[\"INJURIES_REPORTED_NOT_EVIDENT\"] == 0 and", "-  #         row[\"INJURIES_NO_INDICATION\"] == 0", "-  #     )", "-  #     df.loc[idx, \"MOST_SEVERE_INJURY\"] = \"N/A\"", "-", "-  print(\"Number of observations with nan, Intermediate\", df.isnull().any(axis=1).sum())", "-", "-  # Drop observations with latitude and longitude = 0", "-  df = df[df[\"LATITUDE\"] != 0][df[\"LONGITUDE\"] != 0]", "-", "-  # The rest, as described, we just drop", "-  df = df.dropna()", "-", "-  print(\"Number of observations with nan, After\", df.isnull().any(axis=1).sum())", "-  print(\"Number of observations after cleaning:\", len(df.index))", "-", "-  print(\"Writing to csv\")", "-  return df"]}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    df.to_csv(\"clean3.csv\")"], "sub": ["-    df.to_csv(\"clean.csv\")"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 23:12:10 2021 -0600", "msg": "1638421930.1531742_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    df.to_csv(\"clean3.csv\")"], "sub": ["-    df.to_csv(\"clean.csv\")"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\load.py , True, 1638421477.369683 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 23:05:16 2021 -0600", "msg": "1638421477.369683_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\load.py , True, 1638421477.369683 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/load.py b/explore/load.py", "add": ["+  print(\"Number of observations with nan, Before\", df.isnull().any(axis=1).sum())", "+", "+  # Fix BEAT_OF_OCCURENCE", "+  _df = df[df[\"BEAT_OF_OCCURRENCE\"].isna() & df[\"LATITUDE\"].notnull()]", "+", "+  df_with_beat_and_ll = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].notnull()]", "+  for row in _df.iterrows():", "+      idx = row[0]", "+      row = row[1]", "+      latitude = row[\"LATITUDE\"]", "+      longitude = row[\"LONGITUDE\"]", "+      # Get differences", "+      df_with_beat_and_ll[\"latitude diff\"] = abs(df_with_beat_and_ll[\"LATITUDE\"] - latitude)", "+      df_with_beat_and_ll[\"longitude diff\"] = abs(df_with_beat_and_ll[\"LONGITUDE\"] - longitude)", "+      df_with_beat_and_ll[\"abs diff\"] = ((df_with_beat_and_ll[\"latitude diff\"]) ** 2) + (df_with_beat_and_ll[\"longitude diff\"]) ** 2", "+", "+      # Index of row with closest coordinates", "+      closest_idx = df_with_beat_and_ll[\"abs diff\"].idxmin()", "+      # Get beat and insert", "+      predicted_beat = df_with_beat_and_ll.loc[closest_idx, \"BEAT_OF_OCCURRENCE\"]", "+      df.loc[idx, \"BEAT_OF_OCCURRENCE\"] = predicted_beat", "+", "+  # Fix LONGITUDE and LATITUDE", "+  beat_to_ll = {} # Dictionary containing mean latitude and longitude for each beat ID", "+  _df = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].isna() & df[\"LATITUDE\"].isna()]", "+  for row in _df.iterrows():", "+      idx = row[0]", "+      row = row[1]", "+      beat = row[\"BEAT_OF_OCCURRENCE\"]", "+      if beat not in beat_to_ll:", "+          same_beat_df = df_with_beat_and_ll[df_with_beat_and_ll[\"BEAT_OF_OCCURRENCE\"] == beat]", "+", "+          # There are no existing entries of this beat ID that have lat and long values", "+          if not len(same_beat_df.index):", "+              continue", "+", "+          mean_lat = same_beat_df[\"LATITUDE\"].mean()", "+          mean_long = same_beat_df[\"LONGITUDE\"].mean()", "+", "+          beat_to_ll[beat] = (mean_lat, mean_long)", "+      else:", "+          mean_lat, mean_long = beat_to_ll[beat]", "+", "+      df.loc[idx, \"LATITUDE\"] = mean_lat", "+      df.loc[idx, \"LONGITUDE\"] = mean_long", "+", "+  # Fix MOST_SEVERE_INJURY (the 11 observations) -- Update: I chose to drop them instead", "+  # _df = df[", "+  #     df[\"MOST_SEVERE_INJURY\"].isna() &", "+  #     df[\"INJURIES_TOTAL\"].notnull() &", "+  #     df[\"INJURIES_FATAL\"].notnull() &", "+  #     df[\"INJURIES_INCAPACITATING\"].notnull() &", "+  #     df[\"INJURIES_NON_INCAPACITATING\"].notnull() &", "+  #     df[\"INJURIES_REPORTED_NOT_EVIDENT\"].notnull() &", "+  #     df[\"INJURIES_NO_INDICATION\"].notnull()", "+  # ]", "+  # # for row in _df.iterrows():", "+  #     idx = row[0]", "+  #     row = row[1]", "+  #     # Doesn't make sense! See question 1i", "+  #     assert (", "+  #         row[\"INJURIES_FATAL\"] == 0 and", "+  #         row[\"INJURIES_INCAPACITATING\"] == 0 and", "+  #         row[\"INJURIES_NON_INCAPACITATING\"] == 0 and", "+  #         row[\"INJURIES_REPORTED_NOT_EVIDENT\"] == 0 and", "+  #         row[\"INJURIES_NO_INDICATION\"] == 0", "+  #     )", "+  #     df.loc[idx, \"MOST_SEVERE_INJURY\"] = \"N/A\"", "+", "+  print(\"Number of observations with nan, Intermediate\", df.isnull().any(axis=1).sum())", "+", "+  # Drop observations with latitude and longitude = 0", "+  df = df[df[\"LATITUDE\"] != 0][df[\"LONGITUDE\"] != 0]", "+", "+  # The rest, as described, we just drop", "+  df = df.dropna()", "+", "+  print(\"Number of observations with nan, After\", df.isnull().any(axis=1).sum())", "+  print(\"Number of observations after cleaning:\", len(df.index))", "+", "+  print(\"Writing to csv\")", "+  return df"], "sub": ["-", "-  return df #demo"]}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": [], "sub": ["-    # df = copy.deepcopy(dfz)"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 23:04:37 2021 -0600", "msg": "1638421477.369683_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": [], "sub": ["-    # df = copy.deepcopy(dfz)"]}, {"files": "diff --git a/explore/plot_3.png b/explore/plot_3.png", "add": [], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_3.py , True, 1638421042.876718 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 22:57:30 2021 -0600", "msg": "1638421042.876718_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_3.py , True, 1638421042.876718 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/plot_3.py b/explore/plot_3.py", "add": ["+import seaborn as sns", "+  df[\"Severity Score\"] = (", "+    df[\"INJURIES_FATAL\"] * 10 +", "+    df[\"INJURIES_INCAPACITATING\"] * 5 +", "+    df[\"INJURIES_NON_INCAPACITATING\"] * 2 +", "+    df[\"INJURIES_REPORTED_NOT_EVIDENT\"] * 1+", "+    df[\"INJURIES_NO_INDICATION\"] * 0", "+)", "+", "+  df_lighting = df[[\"LIGHTING_CONDITION\", \"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\", \"Severity Score\"]].groupby(\"LIGHTING_CONDITION\")", "+  f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(15, 7.5))", "+  _axes1, _axes2 = axes", "+  i = 0", "+  for lighting, _df in df_lighting:", "+    wc_rc = _df.groupby([\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]).agg('mean').reset_index()", "+    wc_rc = wc_rc.rename(columns={", "+        \"ROADWAY_SURFACE_COND\": \"Roadway Surface Condition\",", "+        \"WEATHER_CONDITION\": \"Weather Condition\"", "+    })", "+    wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Severity Score\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+", "+    # All lightings except daylight do not have blowing sand, soil, dirt as weather", "+    if lighting != \"DAYLIGHT\":", "+        wc_rc[\"blowing sand, soil, dirt\"] = 0", "+", "+    wc_rc = wc_rc.sort_index(axis=1).fillna(0)", "+    if i >= 3:", "+        ax = _axes2[i-3]", "+    else:", "+        ax= _axes1[i]", "+    ax.title.set_text(lighting.lower())", "+    _ax = sns.heatmap(wc_rc, square=True, cmap=\"Blues\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Severity Score\"})", "+    _ax.figure.axes[-1].yaxis.label.set_size(8)", "+    plt.tight_layout()", "+    i += 1", "+  f.suptitle(\"Severity Score by Lighting\", fontsize=20)"], "sub": ["-", "-  plt.scatter(df['A'],df['B'])", "-  return None"]}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    \"\"\"", "+    Question 2", "+    \"\"\"", "+    if False:", "+        df_lighting = df.groupby(\"LIGHTING_CONDITION\")", "+        f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(15, 7.5))", "+        _axes1, _axes2 = axes", "+        i = 0", "+        for lighting, _df in df_lighting:", "+            wc_rc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "+            wc_rc.columns.values[2] = \"Frequency\"", "+            wc_rc = wc_rc.rename(columns={", "+                \"ROADWAY_SURFACE_COND\": \"Roadway Surface Condition\",", "+                \"WEATHER_CONDITION\": \"Weather Condition\"", "+            })", "+            wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+", "+            # All lightings except daylight do not have blowing sand, soil, dirt as weather", "+            if lighting != \"DAYLIGHT\":", "+                wc_rc[\"blowing sand, soil, dirt\"] = 0", "+", "+            wc_rc = wc_rc.sort_index(axis=1).fillna(0)", "+            if i >= 3:", "+                ax = _axes2[i-3]", "+            else:", "+                ax= _axes1[i]", "+            ax.title.set_text(lighting.lower())", "+            _ax = sns.heatmap(wc_rc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})", "+            _ax.figure.axes[-1].yaxis.label.set_size(8)", "+            plt.tight_layout()", "+            i += 1", "+        f.suptitle(\"Crash Frequency by Lighting\", fontsize=20)", "+        plt.show()", "+", "+    \"\"\"", "+    Question 3", "+    \"\"\"", "+    df[\"Severity Score\"] = (", "+        df[\"INJURIES_FATAL\"] * 10 +", "+        df[\"INJURIES_INCAPACITATING\"] * 5 +", "+        df[\"INJURIES_NON_INCAPACITATING\"] * 2 +", "+        df[\"INJURIES_REPORTED_NOT_EVIDENT\"] * 1+", "+        df[\"INJURIES_NO_INDICATION\"] * 0", "+    )", "+", "+    df_lighting = df[[\"LIGHTING_CONDITION\", \"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\", \"Severity Score\"]].groupby(\"LIGHTING_CONDITION\")", "+        wc_rc = _df.groupby([\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]).agg('mean').reset_index()", "+        wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Severity Score\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+        _ax = sns.heatmap(wc_rc, square=True, cmap=\"Blues\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Severity Score\"})", "+    f.suptitle(\"Severity Score by Lighting\", fontsize=20)"], "sub": ["-    df_lighting = df.groupby(\"LIGHTING_CONDITION\")", "-        wc_rc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "-        wc_rc.columns.values[2] = \"Frequency\"", "-        wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "-        _ax = sns.heatmap(wc_rc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})", "-    f.suptitle(\"Crash Frequency by Lighting\", fontsize=20)"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 22:57:23 2021 -0600", "msg": "1638421042.876718_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    \"\"\"", "+    Question 2", "+    \"\"\"", "+    if False:", "+        df_lighting = df.groupby(\"LIGHTING_CONDITION\")", "+        f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(15, 7.5))", "+        _axes1, _axes2 = axes", "+        i = 0", "+        for lighting, _df in df_lighting:", "+            wc_rc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "+            wc_rc.columns.values[2] = \"Frequency\"", "+            wc_rc = wc_rc.rename(columns={", "+                \"ROADWAY_SURFACE_COND\": \"Roadway Surface Condition\",", "+                \"WEATHER_CONDITION\": \"Weather Condition\"", "+            })", "+            wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+", "+            # All lightings except daylight do not have blowing sand, soil, dirt as weather", "+            if lighting != \"DAYLIGHT\":", "+                wc_rc[\"blowing sand, soil, dirt\"] = 0", "+", "+            wc_rc = wc_rc.sort_index(axis=1).fillna(0)", "+            if i >= 3:", "+                ax = _axes2[i-3]", "+            else:", "+                ax= _axes1[i]", "+            ax.title.set_text(lighting.lower())", "+            _ax = sns.heatmap(wc_rc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})", "+            _ax.figure.axes[-1].yaxis.label.set_size(8)", "+            plt.tight_layout()", "+            i += 1", "+        f.suptitle(\"Crash Frequency by Lighting\", fontsize=20)", "+        plt.show()", "+", "+    \"\"\"", "+    Question 3", "+    \"\"\"", "+    df[\"Severity Score\"] = (", "+        df[\"INJURIES_FATAL\"] * 10 +", "+        df[\"INJURIES_INCAPACITATING\"] * 5 +", "+        df[\"INJURIES_NON_INCAPACITATING\"] * 2 +", "+        df[\"INJURIES_REPORTED_NOT_EVIDENT\"] * 1+", "+        df[\"INJURIES_NO_INDICATION\"] * 0", "+    )", "+", "+    df_lighting = df[[\"LIGHTING_CONDITION\", \"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\", \"Severity Score\"]].groupby(\"LIGHTING_CONDITION\")", "+        wc_rc = _df.groupby([\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]).agg('mean').reset_index()", "+        wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Severity Score\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+        _ax = sns.heatmap(wc_rc, square=True, cmap=\"Blues\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Severity Score\"})", "+    f.suptitle(\"Severity Score by Lighting\", fontsize=20)"], "sub": ["-    df_lighting = df.groupby(\"LIGHTING_CONDITION\")", "-        wc_rc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "-        wc_rc.columns.values[2] = \"Frequency\"", "-        wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "-        _ax = sns.heatmap(wc_rc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})", "-    f.suptitle(\"Crash Frequency by Lighting\", fontsize=20)"]}, {"files": "diff --git a/explore/plot_2.png b/explore/plot_2.png", "add": [], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_2.py , True, 1638418981.9668941 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 22:23:11 2021 -0600", "msg": "1638418981.9668941_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_2.py , True, 1638418981.9668941 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/plot_2.py b/explore/plot_2.py", "add": ["+  df_lighting = df.groupby(\"LIGHTING_CONDITION\")", "+  for lighting, _df in df_lighting:", "+    wc_rc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "+    wc_rc.columns.values[2] = \"Frequency\"", "+    wc_rc = wc_rc.rename(columns={", "+    wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+", "+    # All lightings except daylight do not have blowing sand, soil, dirt as weather", "+    if lighting != \"DAYLIGHT\":", "+        wc_rc[\"blowing sand, soil, dirt\"] = 0", "+", "+    wc_rc = wc_rc.sort_index(axis=1).fillna(0)", "+    ax.title.set_text(lighting.lower())", "+    _ax = sns.heatmap(wc_rc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})"], "sub": ["-  df_weather = df.groupby(\"LIGHTING_CONDITION\")", "-  for weather, _df in df_weather:", "-    wc_lc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "-    wc_lc.columns.values[2] = \"Frequency\"", "-    wc_lc = wc_lc.rename(columns={", "-    wc_lc = wc_lc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "-    ax.title.set_text(weather.lower())", "-    _ax = sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})", "-  # plt.show()"]}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    df_lighting = df.groupby(\"LIGHTING_CONDITION\")", "+    for lighting, _df in df_lighting:", "+        wc_rc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "+        wc_rc.columns.values[2] = \"Frequency\"", "+        wc_rc = wc_rc.rename(columns={", "+        wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+", "+        # All lightings except daylight do not have blowing sand, soil, dirt as weather", "+        if lighting != \"DAYLIGHT\":", "+            wc_rc[\"blowing sand, soil, dirt\"] = 0", "+", "+        wc_rc = wc_rc.sort_index(axis=1).fillna(0)", "+        ax.title.set_text(lighting.lower())", "+        _ax = sns.heatmap(wc_rc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})"], "sub": ["-    df_weather = df.groupby(\"LIGHTING_CONDITION\")", "-    for weather, _df in df_weather:", "-        wc_lc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "-        wc_lc.columns.values[2] = \"Frequency\"", "-        wc_lc = wc_lc.rename(columns={", "-        wc_lc = wc_lc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "-        ax.title.set_text(weather.lower())", "-        _ax = sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 22:23:02 2021 -0600", "msg": "1638418981.9668941_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    df_lighting = df.groupby(\"LIGHTING_CONDITION\")", "+    for lighting, _df in df_lighting:", "+        wc_rc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "+        wc_rc.columns.values[2] = \"Frequency\"", "+        wc_rc = wc_rc.rename(columns={", "+        wc_rc = wc_rc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+", "+        # All lightings except daylight do not have blowing sand, soil, dirt as weather", "+        if lighting != \"DAYLIGHT\":", "+            wc_rc[\"blowing sand, soil, dirt\"] = 0", "+", "+        wc_rc = wc_rc.sort_index(axis=1).fillna(0)", "+        ax.title.set_text(lighting.lower())", "+        _ax = sns.heatmap(wc_rc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})"], "sub": ["-    df_weather = df.groupby(\"LIGHTING_CONDITION\")", "-    for weather, _df in df_weather:", "-        wc_lc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "-        wc_lc.columns.values[2] = \"Frequency\"", "-        wc_lc = wc_lc.rename(columns={", "-        wc_lc = wc_lc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "-        ax.title.set_text(weather.lower())", "-        _ax = sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})"]}, {"files": "diff --git a/explore/plot_2.png b/explore/plot_2.png", "add": [], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_2.py , True, 1638416897.7128198 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    f.suptitle(\"Crash Frequency by Lighting\", fontsize=20)"], "sub": ["-    f.suptitle(\"Crash Frequency by Weather\", fontsize=20)"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 21:48:27 2021 -0600", "msg": "1638416897.7128198_end"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    f.suptitle(\"Crash Frequency by Lighting\", fontsize=20)"], "sub": ["-    f.suptitle(\"Crash Frequency by Weather\", fontsize=20)"]}, {"files": "diff --git a/explore/plot_2.py b/explore/plot_2.py", "add": ["+  f.suptitle(\"Crash Frequency by Lighting\", fontsize=20)"], "sub": ["-  f.suptitle(\"Crash Frequency by Weather\", fontsize=20)"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 21:48:17 2021 -0600", "msg": "1638416897.7128198_start"}, {"diffs": [{"files": "diff --git a/explore/plot_2.py b/explore/plot_2.py", "add": ["+  f.suptitle(\"Crash Frequency by Lighting\", fontsize=20)"], "sub": ["-  f.suptitle(\"Crash Frequency by Weather\", fontsize=20)"]}, {"files": "diff --git a/explore/plot_2.png b/explore/plot_2.png", "add": [], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_2.py , True, 1638416837.0141065 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 21:47:25 2021 -0600", "msg": "1638416837.0141065_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_2.py , True, 1638416837.0141065 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/plot_2.py b/explore/plot_2.py", "add": ["+  # plt.show()"], "sub": ["-  plt.show()"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 21:47:17 2021 -0600", "msg": "1638416837.0141065_start"}, {"diffs": [{"files": "diff --git a/explore/plot_2.py b/explore/plot_2.py", "add": ["+  # plt.show()"], "sub": ["-  plt.show()"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_2.py , True, 1638416811.6177015 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 21:47:02 2021 -0600", "msg": "1638416811.6177015_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_2.py , True, 1638416811.6177015 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/plot_2.py b/explore/plot_2.py", "add": ["+  f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(15, 7.5))", "+    _ax = sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})", "+    _ax.figure.axes[-1].yaxis.label.set_size(8)"], "sub": ["-  f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(20, 10))", "-    sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75})"]}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(15, 7.5))", "+        _ax = sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})", "+        _ax.figure.axes[-1].yaxis.label.set_size(8)"], "sub": ["-    f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(20, 10))", "-        sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75})"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 21:46:51 2021 -0600", "msg": "1638416811.6177015_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(15, 7.5))", "+        _ax = sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75, 'label': \"Frequency\"})", "+        _ax.figure.axes[-1].yaxis.label.set_size(8)"], "sub": ["-    f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(20, 10))", "-        sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75})"]}, {"files": "diff --git a/explore/plot_2.png b/explore/plot_2.png", "add": [], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_2.py , False, 1638416560.2553508 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 21:43:10 2021 -0600", "msg": "1638416560.2553508_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_2.py , False, 1638416560.2553508 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_4.py , True, 1638416546.8417509 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 21:42:33 2021 -0600", "msg": "1638416546.8417509_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_4.py , True, 1638416546.8417509 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/plot_2.py b/explore/plot_2.py", "add": ["+from matplotlib.colors import LogNorm", "+import seaborn as sns", "+  df_weather = df.groupby(\"LIGHTING_CONDITION\")", "+  f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(20, 10))", "+  _axes1, _axes2 = axes", "+  i = 0", "+  for weather, _df in df_weather:", "+    wc_lc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "+    wc_lc.columns.values[2] = \"Frequency\"", "+    wc_lc = wc_lc.rename(columns={", "+        \"ROADWAY_SURFACE_COND\": \"Roadway Surface Condition\",", "+        \"WEATHER_CONDITION\": \"Weather Condition\"", "+    })", "+    wc_lc = wc_lc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+    if i >= 3:", "+        ax = _axes2[i-3]", "+    else:", "+        ax= _axes1[i]", "+    ax.title.set_text(weather.lower())", "+    sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75})", "+    plt.tight_layout()", "+    i += 1", "+  f.suptitle(\"Crash Frequency by Weather\", fontsize=20)", "+  plt.show()"], "sub": ["-  plt.scatter(df['A'],df['B'])"]}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+import numpy as np", "+from matplotlib.colors import LogNorm", "+import seaborn as sns", "+    df_weather = df.groupby(\"LIGHTING_CONDITION\")", "+    f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(20, 10))", "+    _axes1, _axes2 = axes", "+    i = 0", "+    for weather, _df in df_weather:", "+        wc_lc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "+        wc_lc.columns.values[2] = \"Frequency\"", "+        wc_lc = wc_lc.rename(columns={", "+            \"ROADWAY_SURFACE_COND\": \"Roadway Surface Condition\",", "+            \"WEATHER_CONDITION\": \"Weather Condition\"", "+        })", "+        wc_lc = wc_lc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+        if i >= 3:", "+            ax = _axes2[i-3]", "+        else:", "+            ax= _axes1[i]", "+        ax.title.set_text(weather.lower())", "+        sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75})", "+        plt.tight_layout()", "+        i += 1", "+    f.suptitle(\"Crash Frequency by Weather\", fontsize=20)", "+    if False:", "+        \"\"\"", "+        Question 4", "+        \"\"\"", "+        # For the purpose of plotting, we will remove geographical outliers", "+        df = df[df[\"LATITUDE\"] > 41.6]", "+        # Plot", "+        df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "+        # Label", "+        plt.xlabel(\"Longitude\")", "+        plt.ylabel(\"Latitude\")", "+        plt.title(\"Occurrence and Frequency of Crashes (Dot = Crash)\")", "+        plt.show()", "+", "+        \"\"\"", "+        Question 5", "+        \"\"\"", "+        groups = df.groupby('ROAD_DEFECT')", "+        fig = plt.figure(figsize=(5, 10))", "+        ax1 = fig.add_subplot(111)", "+", "+        for defect, gp in groups:", "+            if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+                continue", "+            ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+        plt.legend()", "+        plt.xlabel(\"Longitude\")", "+        plt.ylabel(\"Latitude\")", "+        plt.title(\"Crashes by Road Defect\")", "+        plt.show()", "+", "+        if False:", "+            groups = df.groupby('TRAFFICWAY_TYPE')", "+            fig = plt.figure(figsize=(5, 10))", "+            ax1 = fig.add_subplot(111)", "+            for defect, gp in groups:", "+                if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+                    continue", "+                ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+            plt.legend()", "+            plt.xlabel(\"Longitude\")", "+            plt.ylabel(\"Latitude\")", "+            plt.title(\"Crashes by Trafficway Type\")", "+            plt.show()", "+        groups = df.groupby('ALIGNMENT')", "+        fig = plt.figure(figsize=(5, 10))", "+        ax1 = fig.add_subplot(111)", "+        for alignment, gp in groups:", "+            if alignment == \"STRAIGHT AND LEVEL\":", "+                continue", "+            ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "+        plt.legend()", "+        plt.xlabel(\"Longitude\")", "+        plt.ylabel(\"Latitude\")", "+        plt.title(\"Crashes by Alignment\")", "+        plt.show()", "+        _df = df[df[\"POSTED_SPEED_LIMIT\"] > 35]", "+        plt.figure(figsize=(5, 10))", "+        plt.scatter(x=_df['LONGITUDE'], y=_df['LATITUDE'], c=_df['POSTED_SPEED_LIMIT'], cmap=\"hsv\", s=0.5, alpha=0.5)", "+        plt.colorbar()", "+        plt.xlabel(\"Longitude\")", "+        plt.ylabel(\"Latitude\")", "+        plt.title(\"Crashes by Speed Limit\")", "+        plt.show()", "+        return None", "+# cdf = load(\"clean.csv\")"], "sub": ["-    # For the purpose of plotting, we will remove geographical outliers", "-    df = df[df[\"LATITUDE\"] > 41.6]", "-    # Plot", "-    df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "-    # Label", "-    plt.xlabel(\"Longitude\")", "-    plt.ylabel(\"Latitude\")", "-    plt.title(\"Occurrence and Frequency of Crashes (Dot = Crash)\")", "-", "-    # groups = df.groupby('ROAD_DEFECT')", "-    # fig = plt.figure(figsize=(5, 10))", "-    # ax1 = fig.add_subplot(111)", "-    # for defect, gp in groups:", "-    #     if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "-    #         continue", "-    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "-    # plt.legend()", "-    # plt.show()", "-", "-    # groups = df.groupby('TRAFFICWAY_TYPE')", "-    # fig = plt.figure(figsize=(5, 10))", "-    # ax1 = fig.add_subplot(111)", "-    # for defect, gp in groups:", "-    #     if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "-    #         continue", "-    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "-    # plt.legend()", "-    # plt.show()", "-    # groups = df.groupby('ALIGNMENT')", "-    # fig = plt.figure(figsize=(5, 10))", "-    # ax1 = fig.add_subplot(111)", "-    # for alignment, gp in groups:", "-    #     if alignment == \"STRAIGHT AND LEVEL\":", "-    #         continue", "-    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "-    # plt.legend()", "-    # plt.show()", "-    # _df = df[df[\"POSTED_SPEED_LIMIT\"] > 35]", "-    # plt.figure(figsize=(5, 10))", "-    # plt.scatter(x=_df['LONGITUDE'], y=_df['LATITUDE'], c=_df['POSTED_SPEED_LIMIT'], cmap=\"hsv\", s=0.5, alpha=0.5)", "-    # plt.colorbar()", "-    # plt.show()", "-    return None", "-cdf = load(\"clean.csv\")"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 21:42:27 2021 -0600", "msg": "1638416546.8417509_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+import numpy as np", "+from matplotlib.colors import LogNorm", "+import seaborn as sns", "+    df_weather = df.groupby(\"LIGHTING_CONDITION\")", "+    f, axes = plt.subplots(2,3, sharey=True, sharex=True, figsize=(20, 10))", "+    _axes1, _axes2 = axes", "+    i = 0", "+    for weather, _df in df_weather:", "+        wc_lc = _df[[\"ROADWAY_SURFACE_COND\", \"WEATHER_CONDITION\"]].value_counts().reset_index()", "+        wc_lc.columns.values[2] = \"Frequency\"", "+        wc_lc = wc_lc.rename(columns={", "+            \"ROADWAY_SURFACE_COND\": \"Roadway Surface Condition\",", "+            \"WEATHER_CONDITION\": \"Weather Condition\"", "+        })", "+        wc_lc = wc_lc.pivot(\"Roadway Surface Condition\", \"Weather Condition\", \"Frequency\").rename(str.lower, axis='columns').rename(str.lower, axis='index')", "+        if i >= 3:", "+            ax = _axes2[i-3]", "+        else:", "+            ax= _axes1[i]", "+        ax.title.set_text(weather.lower())", "+        sns.heatmap(wc_lc, square=True, norm=LogNorm(), cmap=\"Greens\", ax=ax, cbar_kws={\"shrink\": .75})", "+        plt.tight_layout()", "+        i += 1", "+    f.suptitle(\"Crash Frequency by Weather\", fontsize=20)", "+    if False:", "+        \"\"\"", "+        Question 4", "+        \"\"\"", "+        # For the purpose of plotting, we will remove geographical outliers", "+        df = df[df[\"LATITUDE\"] > 41.6]", "+        # Plot", "+        df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "+        # Label", "+        plt.xlabel(\"Longitude\")", "+        plt.ylabel(\"Latitude\")", "+        plt.title(\"Occurrence and Frequency of Crashes (Dot = Crash)\")", "+        plt.show()", "+", "+        \"\"\"", "+        Question 5", "+        \"\"\"", "+        groups = df.groupby('ROAD_DEFECT')", "+        fig = plt.figure(figsize=(5, 10))", "+        ax1 = fig.add_subplot(111)", "+", "+        for defect, gp in groups:", "+            if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+                continue", "+            ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+        plt.legend()", "+        plt.xlabel(\"Longitude\")", "+        plt.ylabel(\"Latitude\")", "+        plt.title(\"Crashes by Road Defect\")", "+        plt.show()", "+", "+        if False:", "+            groups = df.groupby('TRAFFICWAY_TYPE')", "+            fig = plt.figure(figsize=(5, 10))", "+            ax1 = fig.add_subplot(111)", "+            for defect, gp in groups:", "+                if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+                    continue", "+                ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+            plt.legend()", "+            plt.xlabel(\"Longitude\")", "+            plt.ylabel(\"Latitude\")", "+            plt.title(\"Crashes by Trafficway Type\")", "+            plt.show()", "+        groups = df.groupby('ALIGNMENT')", "+        fig = plt.figure(figsize=(5, 10))", "+        ax1 = fig.add_subplot(111)", "+        for alignment, gp in groups:", "+            if alignment == \"STRAIGHT AND LEVEL\":", "+                continue", "+            ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "+        plt.legend()", "+        plt.xlabel(\"Longitude\")", "+        plt.ylabel(\"Latitude\")", "+        plt.title(\"Crashes by Alignment\")", "+        plt.show()", "+        _df = df[df[\"POSTED_SPEED_LIMIT\"] > 35]", "+        plt.figure(figsize=(5, 10))", "+        plt.scatter(x=_df['LONGITUDE'], y=_df['LATITUDE'], c=_df['POSTED_SPEED_LIMIT'], cmap=\"hsv\", s=0.5, alpha=0.5)", "+        plt.colorbar()", "+        plt.xlabel(\"Longitude\")", "+        plt.ylabel(\"Latitude\")", "+        plt.title(\"Crashes by Speed Limit\")", "+        plt.show()", "+        return None", "+# cdf = load(\"clean.csv\")"], "sub": ["-    # For the purpose of plotting, we will remove geographical outliers", "-    df = df[df[\"LATITUDE\"] > 41.6]", "-    # Plot", "-    df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "-    # Label", "-    plt.xlabel(\"Longitude\")", "-    plt.ylabel(\"Latitude\")", "-    plt.title(\"Occurrence and Frequency of Crashes (Dot = Crash)\")", "-", "-    # groups = df.groupby('ROAD_DEFECT')", "-    # fig = plt.figure(figsize=(5, 10))", "-    # ax1 = fig.add_subplot(111)", "-    # for defect, gp in groups:", "-    #     if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "-    #         continue", "-    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "-    # plt.legend()", "-    # plt.show()", "-", "-    # groups = df.groupby('TRAFFICWAY_TYPE')", "-    # fig = plt.figure(figsize=(5, 10))", "-    # ax1 = fig.add_subplot(111)", "-    # for defect, gp in groups:", "-    #     if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "-    #         continue", "-    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "-    # plt.legend()", "-    # plt.show()", "-    # groups = df.groupby('ALIGNMENT')", "-    # fig = plt.figure(figsize=(5, 10))", "-    # ax1 = fig.add_subplot(111)", "-    # for alignment, gp in groups:", "-    #     if alignment == \"STRAIGHT AND LEVEL\":", "-    #         continue", "-    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "-    # plt.legend()", "-    # plt.show()", "-    # _df = df[df[\"POSTED_SPEED_LIMIT\"] > 35]", "-    # plt.figure(figsize=(5, 10))", "-    # plt.scatter(x=_df['LONGITUDE'], y=_df['LATITUDE'], c=_df['POSTED_SPEED_LIMIT'], cmap=\"hsv\", s=0.5, alpha=0.5)", "-    # plt.colorbar()", "-    # plt.show()", "-    return None", "-cdf = load(\"clean.csv\")"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_4.py , True, 1638412817.416612 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 20:40:22 2021 -0600", "msg": "1638412817.416612_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_4.py , True, 1638412817.416612 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/plot_4.png b/explore/plot_4.png", "add": [], "sub": []}, {"files": "diff --git a/explore/plot_4.py b/explore/plot_4.py", "add": ["+  plt.tight_layout()"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 20:40:17 2021 -0600", "msg": "1638412817.416612_start"}, {"diffs": [{"files": "diff --git a/explore/plot_4.py b/explore/plot_4.py", "add": ["+  plt.tight_layout()"], "sub": []}, {"files": "diff --git a/explore/plot_4.png b/explore/plot_4.png", "add": [], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_4.py , True, 1638412765.6332786 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 20:39:30 2021 -0600", "msg": "1638412765.6332786_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_4.py , True, 1638412765.6332786 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/plot_4.py b/explore/plot_4.py", "add": [], "sub": ["-  plt.show()"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 20:39:25 2021 -0600", "msg": "1638412765.6332786_start"}, {"diffs": [{"files": "diff --git a/explore/plot_4.py b/explore/plot_4.py", "add": [], "sub": ["-  plt.show()"]}, {"files": "diff --git a/explore/plot_4.png b/explore/plot_4.png", "add": [], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_4.py , True, 1638412751.0947342 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 20:39:17 2021 -0600", "msg": "1638412751.0947342_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\plot_4.py , True, 1638412751.0947342 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/plot_4.py b/explore/plot_4.py", "add": ["+  # For the purpose of plotting, we will remove geographical outliers", "+  df = df[df[\"LATITUDE\"] > 41.6]", "+  # Plot", "+  df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "+  # Label", "+  plt.xlabel(\"Longitude\")", "+  plt.ylabel(\"Latitude\")", "+  plt.title(\"Occurrence and Frequency of Crashes (Dot = Crash)\")", "+  plt.show()", "+  cdf = pd.read_csv('clean.csv')", "+  plot(cdf)", "+  plt.savefig('plot_4.png')"], "sub": ["-  plt.scatter(df['A'],df['B'])", "-  return None", "-    cdf = pd.read_csv('clean.csv')", "-    plot(cdf)", "-    plt.savefig('plot_4.png')"]}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    # For the purpose of plotting, we will remove geographical outliers", "+    # Plot", "+    df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "+    # Label", "+    plt.xlabel(\"Longitude\")", "+    plt.ylabel(\"Latitude\")", "+    plt.title(\"Occurrence and Frequency of Crashes (Dot = Crash)\")", "+    plt.show()", "+", "+    # groups = df.groupby('ROAD_DEFECT')", "+", "+    # fig = plt.figure(figsize=(5, 10))", "+    # ax1 = fig.add_subplot(111)", "+", "+    # for defect, gp in groups:", "+    #     if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+    #         continue", "+    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+    # plt.legend()", "+    # groups = df.groupby('TRAFFICWAY_TYPE')", "+    # fig = plt.figure(figsize=(5, 10))", "+    # ax1 = fig.add_subplot(111)", "+    # for defect, gp in groups:", "+    #     if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+    #         continue", "+    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+    # plt.legend()", "+    # plt.show()", "+    # groups = df.groupby('ALIGNMENT')", "+    # fig = plt.figure(figsize=(5, 10))", "+    # ax1 = fig.add_subplot(111)", "+", "+    # for alignment, gp in groups:", "+    #     if alignment == \"STRAIGHT AND LEVEL\":", "+    #         continue", "+    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "+    # plt.legend()", "+    # plt.show()", "+", "+    # _df = df[df[\"POSTED_SPEED_LIMIT\"] > 35]", "+    # plt.figure(figsize=(5, 10))", "+    # plt.scatter(x=_df['LONGITUDE'], y=_df['LATITUDE'], c=_df['POSTED_SPEED_LIMIT'], cmap=\"hsv\", s=0.5, alpha=0.5)", "+    # plt.colorbar()", "+    # plt.show()", "+cdf = load(\"clean.csv\")"], "sub": ["-import copy", "-", "-    # # For the purpose of plotting, we will remove geographical outliers", "-    # df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "-    groups = df.groupby('ROAD_DEFECT')", "-    fig = plt.figure(figsize=(5, 10))", "-    ax1 = fig.add_subplot(111)", "-    for defect, gp in groups:", "-        if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "-            continue", "-        ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "-    plt.legend()", "-    plt.show()", "-    groups = df.groupby('ALIGNMENT')", "-    fig = plt.figure(figsize=(5, 10))", "-    ax1 = fig.add_subplot(111)", "-    for alignment, gp in groups:", "-        if alignment == \"STRAIGHT AND LEVEL\":", "-            continue", "-        ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "-    plt.legend()", "-    plt.show()", "-", "-# cdf = load(\"clean.csv\")"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 20:39:11 2021 -0600", "msg": "1638412751.0947342_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    # For the purpose of plotting, we will remove geographical outliers", "+    # Plot", "+    df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "+    # Label", "+    plt.xlabel(\"Longitude\")", "+    plt.ylabel(\"Latitude\")", "+    plt.title(\"Occurrence and Frequency of Crashes (Dot = Crash)\")", "+    plt.show()", "+", "+    # groups = df.groupby('ROAD_DEFECT')", "+", "+    # fig = plt.figure(figsize=(5, 10))", "+    # ax1 = fig.add_subplot(111)", "+", "+    # for defect, gp in groups:", "+    #     if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+    #         continue", "+    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+    # plt.legend()", "+    # groups = df.groupby('TRAFFICWAY_TYPE')", "+    # fig = plt.figure(figsize=(5, 10))", "+    # ax1 = fig.add_subplot(111)", "+    # for defect, gp in groups:", "+    #     if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+    #         continue", "+    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+    # plt.legend()", "+    # plt.show()", "+    # groups = df.groupby('ALIGNMENT')", "+    # fig = plt.figure(figsize=(5, 10))", "+    # ax1 = fig.add_subplot(111)", "+", "+    # for alignment, gp in groups:", "+    #     if alignment == \"STRAIGHT AND LEVEL\":", "+    #         continue", "+    #     ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "+    # plt.legend()", "+    # plt.show()", "+", "+    # _df = df[df[\"POSTED_SPEED_LIMIT\"] > 35]", "+    # plt.figure(figsize=(5, 10))", "+    # plt.scatter(x=_df['LONGITUDE'], y=_df['LATITUDE'], c=_df['POSTED_SPEED_LIMIT'], cmap=\"hsv\", s=0.5, alpha=0.5)", "+    # plt.colorbar()", "+    # plt.show()", "+cdf = load(\"clean.csv\")"], "sub": ["-import copy", "-", "-    # # For the purpose of plotting, we will remove geographical outliers", "-    # df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "-    groups = df.groupby('ROAD_DEFECT')", "-    fig = plt.figure(figsize=(5, 10))", "-    ax1 = fig.add_subplot(111)", "-    for defect, gp in groups:", "-        if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "-            continue", "-        ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "-    plt.legend()", "-    plt.show()", "-    groups = df.groupby('ALIGNMENT')", "-    fig = plt.figure(figsize=(5, 10))", "-    ax1 = fig.add_subplot(111)", "-    for alignment, gp in groups:", "-        if alignment == \"STRAIGHT AND LEVEL\":", "-            continue", "-        ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "-    plt.legend()", "-    plt.show()", "-", "-# cdf = load(\"clean.csv\")"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py , False, 1638409715.4318912 , error_code: 1"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 19:48:37 2021 -0600", "msg": "1638409715.4318912_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py , False, 1638409715.4318912 , error_code: 1"], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py\\ , True, 1638409710.1845434 , error_code: 2"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 19:48:30 2021 -0600", "msg": "1638409710.1845434_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py\\ , True, 1638409710.1845434 , error_code: 2"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    print(\"Number of observations with nan, Before\", df.isnull().any(axis=1).sum())", "+    print(\"Number of observations with nan, Intermediate\", df.isnull().any(axis=1).sum())", "+", "+    # Drop observations with latitude and longitude = 0", "+    df = df[df[\"LATITUDE\"] != 0][df[\"LONGITUDE\"] != 0]", "+", "+    print(\"Number of observations with nan, After\", df.isnull().any(axis=1).sum())", "+    print(\"Number of observations after cleaning:\", len(df.index))", "+    print(\"Writing to csv\")", "+#%% 2.", "+def plot(df):", "+    '''plot(df) takes as input a clean dataframe and generates a plot. The", "+    style of the plot and variables are up to you.", "+    '''", "+    # # For the purpose of plotting, we will remove geographical outliers", "+    df = df[df[\"LATITUDE\"] > 41.6]", "+    # df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "+    # plt.show()", "+", "+    groups = df.groupby('ROAD_DEFECT')", "+", "+    fig = plt.figure(figsize=(5, 10))", "+    ax1 = fig.add_subplot(111)", "+", "+    for defect, gp in groups:", "+        if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+            continue", "+        ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+    plt.legend()", "+    plt.show()", "+", "+    groups = df.groupby('ALIGNMENT')", "+", "+    fig = plt.figure(figsize=(5, 10))", "+    ax1 = fig.add_subplot(111)", "+    for alignment, gp in groups:", "+        if alignment == \"STRAIGHT AND LEVEL\":", "+            continue", "+        ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "+    plt.legend()", "+    plt.show()", "+", "+    return None", "+", "+# cdf = load(\"clean.csv\")", "+plot(cdf)", "+", "+#%%", "+    # cdf = load(\"clean.csv\")", "+", "+# %%"], "sub": ["-    print(\"Number of Observations with nan, Before\", df.isnull().any(axis=1).sum())", "-    print(\"Number of Observations with nan, Intermediate\", df.isnull().any(axis=1).sum())", "-    print(\"Number of Observations with nan, After\", df.isnull().any(axis=1).sum())", "-    print(\"Number of Observations after cleaning:\", len(df.index))", "-#%%", "-", "-#TODO 2.", "-def plot(df):", "-    '''plot(df) takes as input a clean dataframe and generates a plot. The", "-    style of the plot and variables are up to you.", "-    '''", "-", "-    plt.scatter(df['A'],df['B'])", "-    return None", "-", "-    print(\"df\", df)"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 19:48:30 2021 -0600", "msg": "1638409710.1845434_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    print(\"Number of observations with nan, Before\", df.isnull().any(axis=1).sum())", "+    print(\"Number of observations with nan, Intermediate\", df.isnull().any(axis=1).sum())", "+", "+    # Drop observations with latitude and longitude = 0", "+    df = df[df[\"LATITUDE\"] != 0][df[\"LONGITUDE\"] != 0]", "+", "+    print(\"Number of observations with nan, After\", df.isnull().any(axis=1).sum())", "+    print(\"Number of observations after cleaning:\", len(df.index))", "+    print(\"Writing to csv\")", "+#%% 2.", "+def plot(df):", "+    '''plot(df) takes as input a clean dataframe and generates a plot. The", "+    style of the plot and variables are up to you.", "+    '''", "+    # # For the purpose of plotting, we will remove geographical outliers", "+    df = df[df[\"LATITUDE\"] > 41.6]", "+    # df.plot.scatter(x='LONGITUDE', y='LATITUDE', s=1, alpha=0.006, figsize=(5, 10))", "+    # plt.show()", "+", "+    groups = df.groupby('ROAD_DEFECT')", "+", "+    fig = plt.figure(figsize=(5, 10))", "+    ax1 = fig.add_subplot(111)", "+", "+    for defect, gp in groups:", "+        if defect == \"UNKNOWN\" or defect == \"NO DEFECTS\":", "+            continue", "+        ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=defect)", "+    plt.legend()", "+    plt.show()", "+", "+    groups = df.groupby('ALIGNMENT')", "+", "+    fig = plt.figure(figsize=(5, 10))", "+    ax1 = fig.add_subplot(111)", "+    for alignment, gp in groups:", "+        if alignment == \"STRAIGHT AND LEVEL\":", "+            continue", "+        ax1.scatter(x=gp['LONGITUDE'], y=gp['LATITUDE'], s=1, alpha=1, label=alignment)", "+    plt.legend()", "+    plt.show()", "+", "+    return None", "+", "+# cdf = load(\"clean.csv\")", "+plot(cdf)", "+", "+#%%", "+    # cdf = load(\"clean.csv\")", "+", "+# %%"], "sub": ["-    print(\"Number of Observations with nan, Before\", df.isnull().any(axis=1).sum())", "-    print(\"Number of Observations with nan, Intermediate\", df.isnull().any(axis=1).sum())", "-    print(\"Number of Observations with nan, After\", df.isnull().any(axis=1).sum())", "-    print(\"Number of Observations after cleaning:\", len(df.index))", "-#%%", "-", "-#TODO 2.", "-def plot(df):", "-    '''plot(df) takes as input a clean dataframe and generates a plot. The", "-    style of the plot and variables are up to you.", "-    '''", "-", "-    plt.scatter(df['A'],df['B'])", "-    return None", "-", "-    print(\"df\", df)"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py , True, 1638403385.656909 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 18:03:43 2021 -0600", "msg": "1638403385.656909_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py , True, 1638403385.656909 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    df.to_csv(\"clean.csv\")", "+    df = load('data_2.csv')", "+    print(\"df\", df)", "+    cdf = clean(df)"], "sub": ["-    # df = load('data_2.csv')", "-    # print(\"df\", df)", "-    # cdf = clean(df)", "-    pass"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 18:03:05 2021 -0600", "msg": "1638403385.656909_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    df.to_csv(\"clean.csv\")", "+    df = load('data_2.csv')", "+    print(\"df\", df)", "+    cdf = clean(df)"], "sub": ["-    # df = load('data_2.csv')", "-    # print(\"df\", df)", "-    # cdf = clean(df)", "-    pass"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py , True, 1638403317.3046677 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 18:01:58 2021 -0600", "msg": "1638403317.3046677_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py , True, 1638403317.3046677 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    pass"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 18:01:57 2021 -0600", "msg": "1638403317.3046677_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    pass"], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py , True, 1638403313.4066076 , error_code: 1"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 18:01:53 2021 -0600", "msg": "1638403313.4066076_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+.\\scratch.py , True, 1638403313.4066076 , error_code: 1"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    # df = load('data_2.csv')", "+    # print(\"df\", df)", "+    # cdf = clean(df)"], "sub": ["-df = load('data_2.csv')", "-clean(df)", "-    df = load('data_2.csv')", "-    print(\"df\", df)", "-    cdf = clean(df)"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 18:01:53 2021 -0600", "msg": "1638403313.4066076_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    # df = load('data_2.csv')", "+    # print(\"df\", df)", "+    # cdf = clean(df)"], "sub": ["-df = load('data_2.csv')", "-clean(df)", "-    df = load('data_2.csv')", "-    print(\"df\", df)", "-    cdf = clean(df)"]}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+import copy", "+", "+    Fill in missing values when appropriate", "+    # LATITUDE", "+    # LONGITUDE", "+    # BEAT_OF_OCCURRENCE", "+", "+    # MOST_SEVERE_INJURY (?)", "+", "+    Do not fill in missing values", "+    # STREET_DIRECTION", "+    # STREET_NAME", "+    # INJURIES_TOTAL", "+    # INJURIES_FATAL", "+    # INJURIES_INCAPACITATING", "+    # INJURIES_NON_INCAPACITATING", "+    # INJURIES_REPORTED_NOT_EVIDENT", "+    # INJURIES_NO_INDICATION", "+    # df = copy.deepcopy(dfz)", "+    print(\"Number of Observations with nan, Before\", df.isnull().any(axis=1).sum())", "+", "+        df_with_beat_and_ll[\"abs diff\"] = ((df_with_beat_and_ll[\"latitude diff\"]) ** 2) + (df_with_beat_and_ll[\"longitude diff\"]) ** 2", "+    # Fix LONGITUDE and LATITUDE", "+    # Fix MOST_SEVERE_INJURY (the 11 observations) -- Update: I chose to drop them instead", "+    # _df = df[", "+    #     df[\"MOST_SEVERE_INJURY\"].isna() &", "+    #     df[\"INJURIES_TOTAL\"].notnull() &", "+    #     df[\"INJURIES_FATAL\"].notnull() &", "+    #     df[\"INJURIES_INCAPACITATING\"].notnull() &", "+    #     df[\"INJURIES_NON_INCAPACITATING\"].notnull() &", "+    #     df[\"INJURIES_REPORTED_NOT_EVIDENT\"].notnull() &", "+    #     df[\"INJURIES_NO_INDICATION\"].notnull()", "+    # ]", "+    # # for row in _df.iterrows():", "+    #     idx = row[0]", "+    #     row = row[1]", "+    #     # Doesn't make sense! See question 1i", "+    #     assert (", "+    #         row[\"INJURIES_FATAL\"] == 0 and", "+    #         row[\"INJURIES_INCAPACITATING\"] == 0 and", "+    #         row[\"INJURIES_NON_INCAPACITATING\"] == 0 and", "+    #         row[\"INJURIES_REPORTED_NOT_EVIDENT\"] == 0 and", "+    #         row[\"INJURIES_NO_INDICATION\"] == 0", "+    #     )", "+    #     df.loc[idx, \"MOST_SEVERE_INJURY\"] = \"N/A\"", "+", "+    print(\"Number of Observations with nan, Intermediate\", df.isnull().any(axis=1).sum())", "+    # The rest, as described, we just drop", "+    df = df.dropna()", "+", "+    print(\"Number of Observations with nan, After\", df.isnull().any(axis=1).sum())", "+    print(\"Number of Observations after cleaning:\", len(df.index))", "+", "+    return df", "+", "+df = load('data_2.csv')"], "sub": ["-        df_with_beat_and_ll[\"abs diff\"] = df_with_beat_and_ll[\"latitude diff\"] + df_with_beat_and_ll[\"longitude diff\"]", "-    # Fix longitude and latitude", "-    # Fix MOST_SEVERE_INJURY (the 11 observations)", "-", "-", "-", "-    # MOST_SEVERE_INJURY", "-    # LATITUDE", "-    # LONGITUDE", "-    # BEAT_OF_OCCURRENCE", "-", "-    # STREET_DIRECTION", "-    # STREET_NAME", "-    # MOST_SEVERE_INJURY * (NOT FOR THE 11)", "-    # INJURIES_TOTAL", "-    # INJURIES_FATAL", "-    # INJURIES_INCAPACITATING", "-    # INJURIES_NON_INCAPACITATING", "-    # INJURIES_REPORTED_NOT_EVIDENT", "-    # INJURIES_NO_INDICATION", "-", "-    # return df #demo", "-", "-# df = load('data_2.csv')", "-# df = load('data_2.csv')"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 18:01:01 2021 -0600", "msg": "1638403260.8628576_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+import copy", "+", "+    Fill in missing values when appropriate", "+    # LATITUDE", "+    # LONGITUDE", "+    # BEAT_OF_OCCURRENCE", "+", "+    # MOST_SEVERE_INJURY (?)", "+", "+    Do not fill in missing values", "+    # STREET_DIRECTION", "+    # STREET_NAME", "+    # INJURIES_TOTAL", "+    # INJURIES_FATAL", "+    # INJURIES_INCAPACITATING", "+    # INJURIES_NON_INCAPACITATING", "+    # INJURIES_REPORTED_NOT_EVIDENT", "+    # INJURIES_NO_INDICATION", "+    # df = copy.deepcopy(dfz)", "+    print(\"Number of Observations with nan, Before\", df.isnull().any(axis=1).sum())", "+", "+        df_with_beat_and_ll[\"abs diff\"] = ((df_with_beat_and_ll[\"latitude diff\"]) ** 2) + (df_with_beat_and_ll[\"longitude diff\"]) ** 2", "+    # Fix LONGITUDE and LATITUDE", "+    # Fix MOST_SEVERE_INJURY (the 11 observations) -- Update: I chose to drop them instead", "+    # _df = df[", "+    #     df[\"MOST_SEVERE_INJURY\"].isna() &", "+    #     df[\"INJURIES_TOTAL\"].notnull() &", "+    #     df[\"INJURIES_FATAL\"].notnull() &", "+    #     df[\"INJURIES_INCAPACITATING\"].notnull() &", "+    #     df[\"INJURIES_NON_INCAPACITATING\"].notnull() &", "+    #     df[\"INJURIES_REPORTED_NOT_EVIDENT\"].notnull() &", "+    #     df[\"INJURIES_NO_INDICATION\"].notnull()", "+    # ]", "+    # # for row in _df.iterrows():", "+    #     idx = row[0]", "+    #     row = row[1]", "+    #     # Doesn't make sense! See question 1i", "+    #     assert (", "+    #         row[\"INJURIES_FATAL\"] == 0 and", "+    #         row[\"INJURIES_INCAPACITATING\"] == 0 and", "+    #         row[\"INJURIES_NON_INCAPACITATING\"] == 0 and", "+    #         row[\"INJURIES_REPORTED_NOT_EVIDENT\"] == 0 and", "+    #         row[\"INJURIES_NO_INDICATION\"] == 0", "+    #     )", "+    #     df.loc[idx, \"MOST_SEVERE_INJURY\"] = \"N/A\"", "+", "+    print(\"Number of Observations with nan, Intermediate\", df.isnull().any(axis=1).sum())", "+    # The rest, as described, we just drop", "+    df = df.dropna()", "+", "+    print(\"Number of Observations with nan, After\", df.isnull().any(axis=1).sum())", "+    print(\"Number of Observations after cleaning:\", len(df.index))", "+", "+    return df", "+", "+df = load('data_2.csv')"], "sub": ["-        df_with_beat_and_ll[\"abs diff\"] = df_with_beat_and_ll[\"latitude diff\"] + df_with_beat_and_ll[\"longitude diff\"]", "-    # Fix longitude and latitude", "-    # Fix MOST_SEVERE_INJURY (the 11 observations)", "-", "-", "-", "-    # MOST_SEVERE_INJURY", "-    # LATITUDE", "-    # LONGITUDE", "-    # BEAT_OF_OCCURRENCE", "-", "-    # STREET_DIRECTION", "-    # STREET_NAME", "-    # MOST_SEVERE_INJURY * (NOT FOR THE 11)", "-    # INJURIES_TOTAL", "-    # INJURIES_FATAL", "-    # INJURIES_INCAPACITATING", "-    # INJURIES_NON_INCAPACITATING", "-    # INJURIES_REPORTED_NOT_EVIDENT", "-    # INJURIES_NO_INDICATION", "-", "-    # return df #demo", "-", "-# df = load('data_2.csv')", "-# df = load('data_2.csv')"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638396608.0882294 , error_code: 1"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 16:10:09 2021 -0600", "msg": "1638396608.0882294_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638396608.0882294 , error_code: 1"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    '''load(filename) takes as input a filename and loads a dataframe.", "+    '''", "+    return pd.read_csv(filename, index_col=0)", "+#%%", "+    '''clean(df) takes as input a dataframe and fixes any data errors", "+    '''", "+    # Fix BEAT_OF_OCCURENCE", "+    _df = df[df[\"BEAT_OF_OCCURRENCE\"].isna() & df[\"LATITUDE\"].notnull()]", "+    df_with_beat_and_ll = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].notnull()]", "+    for row in _df.iterrows():", "+        idx = row[0]", "+        row = row[1]", "+        latitude = row[\"LATITUDE\"]", "+        longitude = row[\"LONGITUDE\"]", "+        # Get differences", "+        df_with_beat_and_ll[\"latitude diff\"] = abs(df_with_beat_and_ll[\"LATITUDE\"] - latitude)", "+        df_with_beat_and_ll[\"longitude diff\"] = abs(df_with_beat_and_ll[\"LONGITUDE\"] - longitude)", "+        df_with_beat_and_ll[\"abs diff\"] = df_with_beat_and_ll[\"latitude diff\"] + df_with_beat_and_ll[\"longitude diff\"]", "+", "+        # Index of row with closest coordinates", "+        closest_idx = df_with_beat_and_ll[\"abs diff\"].idxmin()", "+        # Get beat and insert", "+        predicted_beat = df_with_beat_and_ll.loc[closest_idx, \"BEAT_OF_OCCURRENCE\"]", "+        df.loc[idx, \"BEAT_OF_OCCURRENCE\"] = predicted_beat", "+", "+    # Fix longitude and latitude", "+    beat_to_ll = {} # Dictionary containing mean latitude and longitude for each beat ID", "+    _df = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].isna() & df[\"LATITUDE\"].isna()]", "+    for row in _df.iterrows():", "+        idx = row[0]", "+        row = row[1]", "+        beat = row[\"BEAT_OF_OCCURRENCE\"]", "+        if beat not in beat_to_ll:", "+            same_beat_df = df_with_beat_and_ll[df_with_beat_and_ll[\"BEAT_OF_OCCURRENCE\"] == beat]", "+", "+            # There are no existing entries of this beat ID that have lat and long values", "+            if not len(same_beat_df.index):", "+                continue", "+", "+            mean_lat = same_beat_df[\"LATITUDE\"].mean()", "+            mean_long = same_beat_df[\"LONGITUDE\"].mean()", "+", "+            beat_to_ll[beat] = (mean_lat, mean_long)", "+        else:", "+            mean_lat, mean_long = beat_to_ll[beat]", "+", "+        df.loc[idx, \"LATITUDE\"] = mean_lat", "+        df.loc[idx, \"LONGITUDE\"] = mean_long", "+", "+    # Fix MOST_SEVERE_INJURY (the 11 observations)", "+", "+", "+", "+    # MOST_SEVERE_INJURY", "+    # LATITUDE", "+    # LONGITUDE", "+    # BEAT_OF_OCCURRENCE", "+", "+    # STREET_DIRECTION", "+    # STREET_NAME", "+    # MOST_SEVERE_INJURY * (NOT FOR THE 11)", "+    # INJURIES_TOTAL", "+    # INJURIES_FATAL", "+    # INJURIES_INCAPACITATING", "+    # INJURIES_NON_INCAPACITATING", "+    # INJURIES_REPORTED_NOT_EVIDENT", "+    # INJURIES_NO_INDICATION", "+", "+    # return df #demo", "+", "+# df = load('data_2.csv')", "+# df = load('data_2.csv')", "+clean(df)", "+#%%", "+    '''plot(df) takes as input a clean dataframe and generates a plot. The", "+    style of the plot and variables are up to you.", "+    '''", "+", "+    plt.scatter(df['A'],df['B'])", "+    return None"], "sub": ["-  '''load(filename) takes as input a filename and loads a dataframe.", "-  '''", "-  return pd.read_csv(filename, index_col=0)", "-  '''clean(df) takes as input a dataframe and fixes any data errors", "-  '''", "-", "-  return df #demo", "-  '''plot(df) takes as input a clean dataframe and generates a plot. The", "-  style of the plot and variables are up to you.", "-  '''", "-", "-  plt.scatter(df['A'],df['B'])", "-  return None"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 16:10:08 2021 -0600", "msg": "1638396608.0882294_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    '''load(filename) takes as input a filename and loads a dataframe.", "+    '''", "+    return pd.read_csv(filename, index_col=0)", "+#%%", "+    '''clean(df) takes as input a dataframe and fixes any data errors", "+    '''", "+    # Fix BEAT_OF_OCCURENCE", "+    _df = df[df[\"BEAT_OF_OCCURRENCE\"].isna() & df[\"LATITUDE\"].notnull()]", "+    df_with_beat_and_ll = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].notnull()]", "+    for row in _df.iterrows():", "+        idx = row[0]", "+        row = row[1]", "+        latitude = row[\"LATITUDE\"]", "+        longitude = row[\"LONGITUDE\"]", "+        # Get differences", "+        df_with_beat_and_ll[\"latitude diff\"] = abs(df_with_beat_and_ll[\"LATITUDE\"] - latitude)", "+        df_with_beat_and_ll[\"longitude diff\"] = abs(df_with_beat_and_ll[\"LONGITUDE\"] - longitude)", "+        df_with_beat_and_ll[\"abs diff\"] = df_with_beat_and_ll[\"latitude diff\"] + df_with_beat_and_ll[\"longitude diff\"]", "+", "+        # Index of row with closest coordinates", "+        closest_idx = df_with_beat_and_ll[\"abs diff\"].idxmin()", "+        # Get beat and insert", "+        predicted_beat = df_with_beat_and_ll.loc[closest_idx, \"BEAT_OF_OCCURRENCE\"]", "+        df.loc[idx, \"BEAT_OF_OCCURRENCE\"] = predicted_beat", "+", "+    # Fix longitude and latitude", "+    beat_to_ll = {} # Dictionary containing mean latitude and longitude for each beat ID", "+    _df = df[df[\"BEAT_OF_OCCURRENCE\"].notnull() & df[\"LATITUDE\"].isna() & df[\"LATITUDE\"].isna()]", "+    for row in _df.iterrows():", "+        idx = row[0]", "+        row = row[1]", "+        beat = row[\"BEAT_OF_OCCURRENCE\"]", "+        if beat not in beat_to_ll:", "+            same_beat_df = df_with_beat_and_ll[df_with_beat_and_ll[\"BEAT_OF_OCCURRENCE\"] == beat]", "+", "+            # There are no existing entries of this beat ID that have lat and long values", "+            if not len(same_beat_df.index):", "+                continue", "+", "+            mean_lat = same_beat_df[\"LATITUDE\"].mean()", "+            mean_long = same_beat_df[\"LONGITUDE\"].mean()", "+", "+            beat_to_ll[beat] = (mean_lat, mean_long)", "+        else:", "+            mean_lat, mean_long = beat_to_ll[beat]", "+", "+        df.loc[idx, \"LATITUDE\"] = mean_lat", "+        df.loc[idx, \"LONGITUDE\"] = mean_long", "+", "+    # Fix MOST_SEVERE_INJURY (the 11 observations)", "+", "+", "+", "+    # MOST_SEVERE_INJURY", "+    # LATITUDE", "+    # LONGITUDE", "+    # BEAT_OF_OCCURRENCE", "+", "+    # STREET_DIRECTION", "+    # STREET_NAME", "+    # MOST_SEVERE_INJURY * (NOT FOR THE 11)", "+    # INJURIES_TOTAL", "+    # INJURIES_FATAL", "+    # INJURIES_INCAPACITATING", "+    # INJURIES_NON_INCAPACITATING", "+    # INJURIES_REPORTED_NOT_EVIDENT", "+    # INJURIES_NO_INDICATION", "+", "+    # return df #demo", "+", "+# df = load('data_2.csv')", "+# df = load('data_2.csv')", "+clean(df)", "+#%%", "+    '''plot(df) takes as input a clean dataframe and generates a plot. The", "+    style of the plot and variables are up to you.", "+    '''", "+", "+    plt.scatter(df['A'],df['B'])", "+    return None"], "sub": ["-  '''load(filename) takes as input a filename and loads a dataframe.", "-  '''", "-  return pd.read_csv(filename, index_col=0)", "-  '''clean(df) takes as input a dataframe and fixes any data errors", "-  '''", "-", "-  return df #demo", "-  '''plot(df) takes as input a clean dataframe and generates a plot. The", "-  style of the plot and variables are up to you.", "-  '''", "-", "-  plt.scatter(df['A'],df['B'])", "-  return None"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638392226.6119561 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 14:57:10 2021 -0600", "msg": "1638392226.6119561_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638392226.6119561 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    # plot(cdf)", "+    # plt.show()"], "sub": ["-    plot(cdf)", "-    plt.show()"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 14:57:06 2021 -0600", "msg": "1638392226.6119561_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+    # plot(cdf)", "+    # plt.show()"], "sub": ["-    plot(cdf)", "-    plt.show()"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638392210.4248176 , error_code: 1"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 14:56:54 2021 -0600", "msg": "1638392210.4248176_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638392210.4248176 , error_code: 1"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+def missing_exploration(df):", "+    # Print number of observations", "+    print(\"Number of observations:\", len(df.index))", "+    # Print columns with missing values", "+    for column in df.columns:", "+        if df[column].isna().sum():", "+            print('Column:', column, df[column].dtype, 'Missing Values', df[column].isna().sum())", "+            print('---')", "+def semantic_exploration(df):", "+    # Drop all observations with missing values", "+    df_nona = df.dropna()", "+    print(\"Number of observations with no missing values:\", len(df_nona.index))", "+", "+    \"\"\"", "+    Explore column with semantic errors", "+    1. MOST_SEVERE_INJURY", "+    2. LIGHTING_CONDITIONS", "+    3. INJURIES_TOTAL", "+    4. CRASH_TYPE", "+    \"\"\"", "+    # 1. MOST_SEVERE_INJURY", "+    # Dictionary containing the column names of more severe injuries for each key", "+    d = {", "+        \"FATAL\": [],", "+        \"INCAPACITATING INJURY\": [\"INJURIES_FATAL\"],", "+        \"NONINCAPACITATING INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\"],", "+        \"REPORTED, NOT EVIDENT\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\"],", "+        \"NO INDICATION OF INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\", \"INJURIES_REPORTED_NOT_EVIDENT\"],", "+    }", "+    violation_flag = 0", "+    for row in df_nona.iterrows():", "+        row = row[1]", "+        most_severe_injury = row['MOST_SEVERE_INJURY']", "+        should_be_zero_columns = d[most_severe_injury]", "+        for column in should_be_zero_columns:", "+            if row[column] != 0:", "+                violation_flag = 1", "+                break", "+        if violation_flag:", "+    else:", "+        print(\"All good:\", violation_flag)", "+", "+    # 2. LIGHTING_CONDITIONS", "+    df_lighting = df_nona.groupby(\"LIGHTING_CONDITION\")", "+", "+    for lighting, _df in df_lighting:", "+        count = _df[\"CRASH_HOUR\"].value_counts().sort_index()", "+        count.plot(kind='bar', title=lighting)", "+        plt.show()", "+    # All looks good to me", "+", "+    # 3. INJURIES_TOTAL", "+    for row in df_nona.iterrows():", "+        row = row[1]", "+        if row[\"INJURIES_TOTAL\"] != row[\"INJURIES_FATAL\"] + row[\"INJURIES_INCAPACITATING\"] + row[\"INJURIES_NON_INCAPACITATING\"] + row[\"INJURIES_REPORTED_NOT_EVIDENT\"]:", "+            print(row)", "+            break", "+    else:", "+        print(\"All ok\")", "+    # 4. CRASH_TYPE", "+    df_severe_injury = df_nona.groupby(\"MOST_SEVERE_INJURY\")", "+    for injury, _df in df_severe_injury:", "+        if injury == \"FATAL\" or injury == \"INCAPACITATING INJURY\":", "+            __df = _df[_df[\"CRASH_TYPE\"] == \"NO INJURY / DRIVE AWAY\"]", "+            num_invalid = len(__df.index)", "+            if not num_invalid:", "+                print(injury, \"ok\")", "+            else:", "+                print(injury, num_invalid, \"invalid entries\")", "+    # Two crashes had incapacitating injuries under most_severe_injury, yet crash_type was no injury / drive away", "+", "+#The main() function  of this program", "+if __name__ == \"__main__\":", "+    df = load('data_2.csv')", "+    print(\"df\", df)", "+    cdf = clean(df)", "+    plot(cdf)", "+    plt.show()"], "sub": ["-", "-", "-#The main() function  of this program", "-# if __name__ == \"__main__\":", "-#     df = load('data_2.csv')", "-#     print(\"df\", df)", "-#     cdf = clean(df)", "-#     plot(cdf)", "-#     plt.show()", "-", "-df = load('data_2.csv')", "-print(\"df\", df)", "-#%%", "-# Print number of observations", "-print(\"Number of observations:\", len(df.index))", "-", "-# Print columns with missing values", "-for column in df.columns:", "-    if df[column].isna().sum():", "-        print('Column:', column, df[column].dtype, 'Missing Values', df[column].isna().sum())", "-        print('---')", "-# Drop all observations with missing values", "-df_nona = df.dropna()", "-print(\"Number of observations with no missing values:\", len(df_nona.index))", "-", "-\"\"\"", "-Explore column with semantic errors", "-1. MOST_SEVERE_INJURY", "-2. LIGHTING_CONDITIONS", "-3. INJURIES_TOTAL", "-4. CRASH_TYPE", "-\"\"\"", "-# 1. MOST_SEVERE_INJURY", "-# Dictionary containing the column names of more severe injuries for each key", "-d = {", "-    \"FATAL\": [],", "-    \"INCAPACITATING INJURY\": [\"INJURIES_FATAL\"],", "-    \"NONINCAPACITATING INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\"],", "-    \"REPORTED, NOT EVIDENT\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\"],", "-    \"NO INDICATION OF INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\", \"INJURIES_REPORTED_NOT_EVIDENT\"],", "-}", "-violation_flag = 0", "-for row in df_nona.iterrows():", "-    row = row[1]", "-    most_severe_injury = row['MOST_SEVERE_INJURY']", "-    should_be_zero_columns = d[most_severe_injury]", "-    for column in should_be_zero_columns:", "-        if row[column] != 0:", "-            violation_flag = 1", "-    if violation_flag:", "-        break", "-else:", "-    print(\"All good:\", violation_flag)", "-#%%", "-# 2. LIGHTING_CONDITIONS", "-df_lighting = df_nona.groupby(\"LIGHTING_CONDITION\")", "-for lighting, _df in df_lighting:", "-    count = _df[\"CRASH_HOUR\"].value_counts().sort_index()", "-    count.plot(kind='bar', title=lighting)", "-    plt.show()", "-# All looks good to me", "-# %%", "-# 3. INJURIES_TOTAL", "-for row in df_nona.iterrows():", "-    row = row[1]", "-    if row[\"INJURIES_TOTAL\"] != row[\"INJURIES_FATAL\"] + row[\"INJURIES_INCAPACITATING\"] + row[\"INJURIES_NON_INCAPACITATING\"] + row[\"INJURIES_REPORTED_NOT_EVIDENT\"]:", "-        print(row)", "-        break", "-else:", "-    print(\"All ok\")", "-# %%", "-# 4. CRASH_TYPE", "-df_severe_injury = df_nona.groupby(\"MOST_SEVERE_INJURY\")", "-for injury, _df in df_severe_injury:", "-    if injury == \"FATAL\" or injury == \"INCAPACITATING INJURY\":", "-        __df = _df[_df[\"CRASH_TYPE\"] == \"NO INJURY / DRIVE AWAY\"]", "-        num_invalid = len(__df.index)", "-        if not num_invalid:", "-            print(injury, \"ok\")", "-        else:", "-            print(injury, num_invalid, \"invalid entries\")", "-", "-# Two crashes had incapacitating injuries under most_severe_injury, yet crash_type was no injury / drive away", "-# %%"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 14:56:50 2021 -0600", "msg": "1638392210.4248176_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+def missing_exploration(df):", "+    # Print number of observations", "+    print(\"Number of observations:\", len(df.index))", "+    # Print columns with missing values", "+    for column in df.columns:", "+        if df[column].isna().sum():", "+            print('Column:', column, df[column].dtype, 'Missing Values', df[column].isna().sum())", "+            print('---')", "+def semantic_exploration(df):", "+    # Drop all observations with missing values", "+    df_nona = df.dropna()", "+    print(\"Number of observations with no missing values:\", len(df_nona.index))", "+", "+    \"\"\"", "+    Explore column with semantic errors", "+    1. MOST_SEVERE_INJURY", "+    2. LIGHTING_CONDITIONS", "+    3. INJURIES_TOTAL", "+    4. CRASH_TYPE", "+    \"\"\"", "+    # 1. MOST_SEVERE_INJURY", "+    # Dictionary containing the column names of more severe injuries for each key", "+    d = {", "+        \"FATAL\": [],", "+        \"INCAPACITATING INJURY\": [\"INJURIES_FATAL\"],", "+        \"NONINCAPACITATING INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\"],", "+        \"REPORTED, NOT EVIDENT\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\"],", "+        \"NO INDICATION OF INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\", \"INJURIES_REPORTED_NOT_EVIDENT\"],", "+    }", "+    violation_flag = 0", "+    for row in df_nona.iterrows():", "+        row = row[1]", "+        most_severe_injury = row['MOST_SEVERE_INJURY']", "+        should_be_zero_columns = d[most_severe_injury]", "+        for column in should_be_zero_columns:", "+            if row[column] != 0:", "+                violation_flag = 1", "+                break", "+        if violation_flag:", "+    else:", "+        print(\"All good:\", violation_flag)", "+", "+    # 2. LIGHTING_CONDITIONS", "+    df_lighting = df_nona.groupby(\"LIGHTING_CONDITION\")", "+", "+    for lighting, _df in df_lighting:", "+        count = _df[\"CRASH_HOUR\"].value_counts().sort_index()", "+        count.plot(kind='bar', title=lighting)", "+        plt.show()", "+    # All looks good to me", "+", "+    # 3. INJURIES_TOTAL", "+    for row in df_nona.iterrows():", "+        row = row[1]", "+        if row[\"INJURIES_TOTAL\"] != row[\"INJURIES_FATAL\"] + row[\"INJURIES_INCAPACITATING\"] + row[\"INJURIES_NON_INCAPACITATING\"] + row[\"INJURIES_REPORTED_NOT_EVIDENT\"]:", "+            print(row)", "+            break", "+    else:", "+        print(\"All ok\")", "+    # 4. CRASH_TYPE", "+    df_severe_injury = df_nona.groupby(\"MOST_SEVERE_INJURY\")", "+    for injury, _df in df_severe_injury:", "+        if injury == \"FATAL\" or injury == \"INCAPACITATING INJURY\":", "+            __df = _df[_df[\"CRASH_TYPE\"] == \"NO INJURY / DRIVE AWAY\"]", "+            num_invalid = len(__df.index)", "+            if not num_invalid:", "+                print(injury, \"ok\")", "+            else:", "+                print(injury, num_invalid, \"invalid entries\")", "+    # Two crashes had incapacitating injuries under most_severe_injury, yet crash_type was no injury / drive away", "+", "+#The main() function  of this program", "+if __name__ == \"__main__\":", "+    df = load('data_2.csv')", "+    print(\"df\", df)", "+    cdf = clean(df)", "+    plot(cdf)", "+    plt.show()"], "sub": ["-", "-", "-#The main() function  of this program", "-# if __name__ == \"__main__\":", "-#     df = load('data_2.csv')", "-#     print(\"df\", df)", "-#     cdf = clean(df)", "-#     plot(cdf)", "-#     plt.show()", "-", "-df = load('data_2.csv')", "-print(\"df\", df)", "-#%%", "-# Print number of observations", "-print(\"Number of observations:\", len(df.index))", "-", "-# Print columns with missing values", "-for column in df.columns:", "-    if df[column].isna().sum():", "-        print('Column:', column, df[column].dtype, 'Missing Values', df[column].isna().sum())", "-        print('---')", "-# Drop all observations with missing values", "-df_nona = df.dropna()", "-print(\"Number of observations with no missing values:\", len(df_nona.index))", "-", "-\"\"\"", "-Explore column with semantic errors", "-1. MOST_SEVERE_INJURY", "-2. LIGHTING_CONDITIONS", "-3. INJURIES_TOTAL", "-4. CRASH_TYPE", "-\"\"\"", "-# 1. MOST_SEVERE_INJURY", "-# Dictionary containing the column names of more severe injuries for each key", "-d = {", "-    \"FATAL\": [],", "-    \"INCAPACITATING INJURY\": [\"INJURIES_FATAL\"],", "-    \"NONINCAPACITATING INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\"],", "-    \"REPORTED, NOT EVIDENT\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\"],", "-    \"NO INDICATION OF INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\", \"INJURIES_REPORTED_NOT_EVIDENT\"],", "-}", "-violation_flag = 0", "-for row in df_nona.iterrows():", "-    row = row[1]", "-    most_severe_injury = row['MOST_SEVERE_INJURY']", "-    should_be_zero_columns = d[most_severe_injury]", "-    for column in should_be_zero_columns:", "-        if row[column] != 0:", "-            violation_flag = 1", "-    if violation_flag:", "-        break", "-else:", "-    print(\"All good:\", violation_flag)", "-#%%", "-# 2. LIGHTING_CONDITIONS", "-df_lighting = df_nona.groupby(\"LIGHTING_CONDITION\")", "-for lighting, _df in df_lighting:", "-    count = _df[\"CRASH_HOUR\"].value_counts().sort_index()", "-    count.plot(kind='bar', title=lighting)", "-    plt.show()", "-# All looks good to me", "-# %%", "-# 3. INJURIES_TOTAL", "-for row in df_nona.iterrows():", "-    row = row[1]", "-    if row[\"INJURIES_TOTAL\"] != row[\"INJURIES_FATAL\"] + row[\"INJURIES_INCAPACITATING\"] + row[\"INJURIES_NON_INCAPACITATING\"] + row[\"INJURIES_REPORTED_NOT_EVIDENT\"]:", "-        print(row)", "-        break", "-else:", "-    print(\"All ok\")", "-# %%", "-# 4. CRASH_TYPE", "-df_severe_injury = df_nona.groupby(\"MOST_SEVERE_INJURY\")", "-for injury, _df in df_severe_injury:", "-    if injury == \"FATAL\" or injury == \"INCAPACITATING INJURY\":", "-        __df = _df[_df[\"CRASH_TYPE\"] == \"NO INJURY / DRIVE AWAY\"]", "-        num_invalid = len(__df.index)", "-        if not num_invalid:", "-            print(injury, \"ok\")", "-        else:", "-            print(injury, num_invalid, \"invalid entries\")", "-", "-# Two crashes had incapacitating injuries under most_severe_injury, yet crash_type was no injury / drive away", "-# %%"]}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638388973.2968845 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 14:04:23 2021 -0600", "msg": "1638388973.2968845_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638388973.2968845 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+4. CRASH_TYPE", "+# 4. CRASH_TYPE", "+df_severe_injury = df_nona.groupby(\"MOST_SEVERE_INJURY\")", "+for injury, _df in df_severe_injury:", "+    if injury == \"FATAL\" or injury == \"INCAPACITATING INJURY\":", "+        __df = _df[_df[\"CRASH_TYPE\"] == \"NO INJURY / DRIVE AWAY\"]", "+        num_invalid = len(__df.index)", "+        if not num_invalid:", "+            print(injury, \"ok\")", "+        else:", "+            print(injury, num_invalid, \"invalid entries\")", "+", "+# Two crashes had incapacitating injuries under most_severe_injury, yet crash_type was no injury / drive away", "+", "+# %%"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Wed Dec 1 14:02:53 2021 -0600", "msg": "1638388973.2968845_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+4. CRASH_TYPE", "+# 4. CRASH_TYPE", "+df_severe_injury = df_nona.groupby(\"MOST_SEVERE_INJURY\")", "+for injury, _df in df_severe_injury:", "+    if injury == \"FATAL\" or injury == \"INCAPACITATING INJURY\":", "+        __df = _df[_df[\"CRASH_TYPE\"] == \"NO INJURY / DRIVE AWAY\"]", "+        num_invalid = len(__df.index)", "+        if not num_invalid:", "+            print(injury, \"ok\")", "+        else:", "+            print(injury, num_invalid, \"invalid entries\")", "+", "+# Two crashes had incapacitating injuries under most_severe_injury, yet crash_type was no injury / drive away", "+", "+# %%"], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638337645.7502227 , error_code: 0"], "sub": []}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Tue Nov 30 23:48:51 2021 -0600", "msg": "1638337645.7502227_end"}, {"diffs": [{"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": ["+scratch.py , True, 1638337645.7502227 , error_code: 0"], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+#%%", "+  return pd.read_csv(filename, index_col=0)", "+# if __name__ == \"__main__\":", "+#     df = load('data_2.csv')", "+#     print(\"df\", df)", "+#     cdf = clean(df)", "+#     plot(cdf)", "+#     plt.show()", "+#%%", "+df = load('data_2.csv')", "+print(\"df\", df)", "+", "+#%%", "+# Print number of observations", "+print(\"Number of observations:\", len(df.index))", "+", "+# Print columns with missing values", "+for column in df.columns:", "+    if df[column].isna().sum():", "+        print('Column:', column, df[column].dtype, 'Missing Values', df[column].isna().sum())", "+        print('---')", "+# %%", "+# Drop all observations with missing values", "+df_nona = df.dropna()", "+print(\"Number of observations with no missing values:\", len(df_nona.index))", "+\"\"\"", "+Explore column with semantic errors", "+1. MOST_SEVERE_INJURY", "+2. LIGHTING_CONDITIONS", "+3. INJURIES_TOTAL", "+\"\"\"", "+# 1. MOST_SEVERE_INJURY", "+# Dictionary containing the column names of more severe injuries for each key", "+d = {", "+    \"FATAL\": [],", "+    \"INCAPACITATING INJURY\": [\"INJURIES_FATAL\"],", "+    \"NONINCAPACITATING INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\"],", "+    \"REPORTED, NOT EVIDENT\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\"],", "+    \"NO INDICATION OF INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\", \"INJURIES_REPORTED_NOT_EVIDENT\"],", "+}", "+violation_flag = 0", "+for row in df_nona.iterrows():", "+    row = row[1]", "+    most_severe_injury = row['MOST_SEVERE_INJURY']", "+    should_be_zero_columns = d[most_severe_injury]", "+    for column in should_be_zero_columns:", "+        if row[column] != 0:", "+            violation_flag = 1", "+            break", "+    if violation_flag:", "+        break", "+else:", "+    print(\"All good:\", violation_flag)", "+", "+#%%", "+# 2. LIGHTING_CONDITIONS", "+df_lighting = df_nona.groupby(\"LIGHTING_CONDITION\")", "+", "+for lighting, _df in df_lighting:", "+    count = _df[\"CRASH_HOUR\"].value_counts().sort_index()", "+    count.plot(kind='bar', title=lighting)", "+    plt.show()", "+# All looks good to me", "+# %%", "+# 3. INJURIES_TOTAL", "+for row in df_nona.iterrows():", "+    row = row[1]", "+    if row[\"INJURIES_TOTAL\"] != row[\"INJURIES_FATAL\"] + row[\"INJURIES_INCAPACITATING\"] + row[\"INJURIES_NON_INCAPACITATING\"] + row[\"INJURIES_REPORTED_NOT_EVIDENT\"]:", "+        print(row)", "+        break", "+else:", "+    print(\"All ok\")", "+# %%"], "sub": ["-", "-  return pd.read_csv(filename) #demo", "-if __name__ == \"__main__\":", "-    df = load('data.csv')", "-    cdf = clean(df)", "-    plot(cdf)", "-    plt.show()"]}], "author": "hugo-chan <hugoyhc14@gmail.com>", "date": "Tue Nov 30 23:47:25 2021 -0600", "msg": "1638337645.7502227_start"}, {"diffs": [{"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+#%%", "+  return pd.read_csv(filename, index_col=0)", "+# if __name__ == \"__main__\":", "+#     df = load('data_2.csv')", "+#     print(\"df\", df)", "+#     cdf = clean(df)", "+#     plot(cdf)", "+#     plt.show()", "+#%%", "+df = load('data_2.csv')", "+print(\"df\", df)", "+", "+#%%", "+# Print number of observations", "+print(\"Number of observations:\", len(df.index))", "+", "+# Print columns with missing values", "+for column in df.columns:", "+    if df[column].isna().sum():", "+        print('Column:', column, df[column].dtype, 'Missing Values', df[column].isna().sum())", "+        print('---')", "+# %%", "+# Drop all observations with missing values", "+df_nona = df.dropna()", "+print(\"Number of observations with no missing values:\", len(df_nona.index))", "+\"\"\"", "+Explore column with semantic errors", "+1. MOST_SEVERE_INJURY", "+2. LIGHTING_CONDITIONS", "+3. INJURIES_TOTAL", "+\"\"\"", "+# 1. MOST_SEVERE_INJURY", "+# Dictionary containing the column names of more severe injuries for each key", "+d = {", "+    \"FATAL\": [],", "+    \"INCAPACITATING INJURY\": [\"INJURIES_FATAL\"],", "+    \"NONINCAPACITATING INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\"],", "+    \"REPORTED, NOT EVIDENT\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\"],", "+    \"NO INDICATION OF INJURY\": [\"INJURIES_FATAL\", \"INJURIES_INCAPACITATING\", \"INJURIES_NON_INCAPACITATING\", \"INJURIES_REPORTED_NOT_EVIDENT\"],", "+}", "+violation_flag = 0", "+for row in df_nona.iterrows():", "+    row = row[1]", "+    most_severe_injury = row['MOST_SEVERE_INJURY']", "+    should_be_zero_columns = d[most_severe_injury]", "+    for column in should_be_zero_columns:", "+        if row[column] != 0:", "+            violation_flag = 1", "+            break", "+    if violation_flag:", "+        break", "+else:", "+    print(\"All good:\", violation_flag)", "+", "+#%%", "+# 2. LIGHTING_CONDITIONS", "+df_lighting = df_nona.groupby(\"LIGHTING_CONDITION\")", "+", "+for lighting, _df in df_lighting:", "+    count = _df[\"CRASH_HOUR\"].value_counts().sort_index()", "+    count.plot(kind='bar', title=lighting)", "+    plt.show()", "+# All looks good to me", "+# %%", "+# 3. INJURIES_TOTAL", "+for row in df_nona.iterrows():", "+    row = row[1]", "+    if row[\"INJURIES_TOTAL\"] != row[\"INJURIES_FATAL\"] + row[\"INJURIES_INCAPACITATING\"] + row[\"INJURIES_NON_INCAPACITATING\"] + row[\"INJURIES_REPORTED_NOT_EVIDENT\"]:", "+        print(row)", "+        break", "+else:", "+    print(\"All ok\")", "+# %%"], "sub": ["-", "-  return pd.read_csv(filename) #demo", "-if __name__ == \"__main__\":", "-    df = load('data.csv')", "-    cdf = clean(df)", "-    plot(cdf)", "-    plt.show()"]}, {"files": "diff --git a/.DS_Store b/.DS_Store", "add": [], "sub": []}, {"files": "diff --git a/.gitignore b/.gitignore", "add": ["+*.csv"], "sub": []}, {"files": "diff --git a/README.md b/README.md", "add": ["+# README", "+", "+cnet_id: #", "+", "+name: #"], "sub": []}, {"files": "diff --git a/explore/data.csv b/explore/data.csv", "add": ["+A,B", "+1,2", "+3,4", "+5,0"], "sub": []}, {"files": "diff --git a/explore/load.py b/explore/load.py", "add": ["+'''load.py Load loads the dataset, cleans it, and generates a new clean", "+csv file.", "+'''", "+", "+#standard imports", "+import pandas as pd", "+", "+", "+def load(filename):", "+  '''load(filename) takes as input a filename and loads a dataframe.", "+  '''", "+  return pd.read_csv(filename) #demo", "+", "+", "+def clean(df):", "+  '''clean(df) takes as input a dataframe and fixes any data errors", "+     *that might affect your results*. it returns a copy of the dataframe", "+     without errors.", "+  '''", "+", "+  return df #demo", "+", "+", "+#The main() function  of this program", "+", "+if __name__ == \"__main__\":", "+    df = load('data_2.csv')", "+    cdf = clean(df)", "+    cdf.to_csv('clean.csv')"], "sub": []}, {"files": "diff --git a/explore/plot_2.py b/explore/plot_2.py", "add": ["+'''plot.py Plot loads data from the clean csv file and produces a plot that is saved.", "+'''", "+", "+#standard imports", "+import pandas as pd", "+import matplotlib.pyplot as plt", "+", "+", "+def plot(df):", "+  '''plot(df) takes as input a clean dataframe and generates a plot. The", "+  style of the plot and variables are up to you.", "+  '''", "+  plt.scatter(df['A'],df['B'])", "+  return None", "+", "+", "+", "+#The main() function  of this program", "+if __name__ == \"__main__\":", "+    cdf = pd.read_csv('clean.csv')", "+    plot(cdf)", "+    plt.savefig('plot_2.png')"], "sub": []}, {"files": "diff --git a/explore/plot_3.py b/explore/plot_3.py", "add": ["+'''plot.py Plot loads data from the clean csv file and produces a plot that is saved.", "+'''", "+", "+#standard imports", "+import pandas as pd", "+import matplotlib.pyplot as plt", "+", "+", "+def plot(df):", "+  '''plot(df) takes as input a clean dataframe and generates a plot. The", "+  style of the plot and variables are up to you.", "+  '''", "+  plt.scatter(df['A'],df['B'])", "+  return None", "+", "+", "+", "+#The main() function  of this program", "+if __name__ == \"__main__\":", "+    cdf = pd.read_csv('clean.csv')", "+    plot(cdf)", "+    plt.savefig('plot_3.png')"], "sub": []}, {"files": "diff --git a/explore/plot_4.py b/explore/plot_4.py", "add": ["+'''plot.py Plot loads data from the clean csv file and produces a plot that is saved.", "+'''", "+", "+#standard imports", "+import pandas as pd", "+import matplotlib.pyplot as plt", "+", "+", "+def plot(df):", "+  '''plot(df) takes as input a clean dataframe and generates a plot. The", "+  style of the plot and variables are up to you.", "+  '''", "+  plt.scatter(df['A'],df['B'])", "+  return None", "+", "+", "+", "+#The main() function  of this program", "+if __name__ == \"__main__\":", "+    cdf = pd.read_csv('clean.csv')", "+    plot(cdf)", "+    plt.savefig('plot_4.png')"], "sub": []}, {"files": "diff --git a/explore/run.py b/explore/run.py", "add": ["+\"\"\"This python program executes your code", "+\"\"\"", "+", "+from git import Repo", "+import os", "+import time", "+import sys", "+import subprocess", "+", "+", "+#advanced feature change at your own risk", "+COMPILER_COMMAND = 'python' # replace with whatever usually used in the commandline ex. python3", "+", "+", "+", "+def check_diff(repo):", "+    hcommit = repo.head.commit", "+", "+    diffs = hcommit.diff(None)", "+", "+    if len(diffs) == 0:", "+        return False", "+    else:", "+        return True", "+", "+", "+def add_commit(id, check_changed = True, push = True):", "+    \"\"\"", "+    Add current changes and commit", "+    \"\"\"", "+    # need to check if anything in repo has changed", "+    repo = Repo(os.path.dirname(os.getcwd())) #changed to look at the parent", "+", "+    if check_changed:", "+        changed = check_diff(repo)", "+    else:", "+        changed = True", "+", "+    if changed:", "+        repo.git.add('.')", "+", "+        repo.git.commit('-m', id)", "+        if push:", "+            repo.remotes.origin.push()", "+        return changed", "+", "+    else:", "+        return changed", "+", "+", "+if __name__ == '__main__':", "+", "+    ##error checking", "+    if len(sys.argv) == 1:", "+        print(\"You must run the program as follows:\\n python run.py scratch.py \\n or \\n python run.py load.py \\n or \\n python run.py plot.py\")", "+        exit()", "+", "+", "+    id = str(time.time())", "+    committed = add_commit(id + '_start', push = False)", "+", "+    command = [COMPILER_COMMAND] + sys.argv[1:]", "+", "+    process = subprocess.run(command)", "+", "+    with open('./runs.txt', 'a') as f:", "+        record = '{} , {}, {} , error_code: {} \\n'.format(sys.argv[1], committed, id, process.returncode)", "+        f.write(record)", "+", "+    add_commit(id + '_end', check_changed = False, push=True)"], "sub": []}, {"files": "diff --git a/explore/runs.txt b/explore/runs.txt", "add": [], "sub": []}, {"files": "diff --git a/explore/scratch.py b/explore/scratch.py", "add": ["+'''scratch.py", "+", "+You will write down any \"scratch\" code that you use to explore the dataset in", "+this file. This code does not produce any outputs (it does not modify any files)", "+but allows you to explore the data. We're separating this code from the rest because", "+it allows us to understand your thought process during data exploration.", "+", "+*Remember to replace the return statements with your code*", "+'''", "+", "+#standard imports", "+import pandas as pd", "+import matplotlib.pyplot as plt", "+", "+", "+#TODO 1.", "+def load(filename):", "+  '''load(filename) takes as input a filename and loads a dataframe.", "+  '''", "+  return pd.read_csv(filename) #demo", "+", "+def clean(df):", "+  '''clean(df) takes as input a dataframe and fixes any data errors", "+     *that might affect your results*. it returns a copy of the dataframe", "+     without errors.", "+  '''", "+", "+  return df #demo", "+", "+", "+#TODO 2.", "+def plot(df):", "+  '''plot(df) takes as input a clean dataframe and generates a plot. The", "+  style of the plot and variables are up to you.", "+  '''", "+", "+  plt.scatter(df['A'],df['B'])", "+  return None", "+", "+", "+", "+#The main() function  of this program", "+", "+if __name__ == \"__main__\":", "+    df = load('data.csv')", "+    cdf = clean(df)", "+    plot(cdf)", "+    plt.show()", "+", "+"], "sub": []}, {"files": "diff --git a/requirements.txt b/requirements.txt", "add": ["+appnope==0.1.2", "+argon2-cffi==20.1.0", "+async-generator==1.10", "+attrs==21.2.0", "+backcall==0.2.0", "+bitstring==3.1.9", "+bleach==3.3.0", "+cffi==1.14.5", "+click==8.0.0", "+cloudpickle==1.6.0", "+cycler==0.10.0", "+dask==2021.4.1", "+decorator==5.0.7", "+defusedxml==0.7.1", "+distributed==2021.4.1", "+entrypoints==0.3", "+fsspec==2021.5.0", "+gitdb==4.0.9", "+GitPython==3.1.24", "+graphviz==0.16", "+HeapDict==1.0.1", "+ipykernel==5.5.5", "+ipython==7.23.1", "+ipython-genutils==0.2.0", "+ipywidgets==7.6.3", "+jedi==0.18.0", "+Jinja2==3.0.0", "+joblib==1.0.1", "+jsonschema==3.2.0", "+jupyter==1.0.0", "+jupyter-client==6.1.12", "+jupyter-console==6.4.0", "+jupyter-core==4.7.1", "+jupyterlab-pygments==0.1.2", "+jupyterlab-widgets==1.0.0", "+kiwisolver==1.3.1", "+locket==0.2.1", "+MarkupSafe==2.0.0", "+matplotlib==3.4.2", "+matplotlib-inline==0.1.2", "+mistune==0.8.4", "+msgpack==1.0.2", "+nbclient==0.5.3", "+nbconvert==6.0.7", "+nbformat==5.1.3", "+nest-asyncio==1.5.1", "+notebook==6.3.0", "+numpy==1.20.3", "+packaging==20.9", "+pandas==1.2.4", "+pandocfilters==1.4.3", "+parso==0.8.2", "+partd==1.2.0", "+pexpect==4.8.0", "+pickleshare==0.7.5", "+Pillow==8.2.0", "+prometheus-client==0.10.1", "+prompt-toolkit==3.0.18", "+psutil==5.8.0", "+ptyprocess==0.7.0", "+pycparser==2.20", "+Pygments==2.9.0", "+pyparsing==2.4.7", "+pyrsistent==0.17.3", "+python-dateutil==2.8.1", "+pytz==2021.1", "+PyYAML==5.4.1", "+pyzmq==22.0.3", "+qtconsole==5.1.0", "+QtPy==1.9.0", "+scikit-learn==0.24.2", "+scipy==1.6.3", "+Send2Trash==1.5.0", "+six==1.16.0", "+sklearn==0.0", "+smmap==5.0.0", "+sortedcontainers==2.3.0", "+tblib==1.7.0", "+terminado==0.9.5", "+testpath==0.4.4", "+threadpoolctl==2.1.0", "+toolz==0.11.1", "+tornado==6.1", "+traitlets==5.0.5", "+typing-extensions==3.10.0.2", "+wcwidth==0.2.5", "+webencodings==0.5.1", "+widgetsnbextension==3.5.1", "+zict==2.0.0"], "sub": []}], "author": "github-classroom[bot] <66690702+github-classroom[bot]@users.noreply.github.com>", "date": "Fri Nov 19 20:11:43 2021 +0000", "msg": "Initial commit"}]